{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name: lcms_data_processing\n",
    "date: 08/20/2024\n",
    "version: 1.0\n",
    "author: Justin Sankey\n",
    "\n",
    "description: Takes raw liquit chromatography mass spectroscopy (LCMS) data, \n",
    "extracts relevant paramters for analysis and writes them to excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute the notebook for the first time you need to install all required python packages.\n",
    "So, type the following commands in your python console or anaconda prompt:\n",
    "- pip install pandas\n",
    "- pip install numpy\n",
    "- pip install matplotlib\n",
    "- pip install seaborn\n",
    "- pip install scikit-learn\n",
    "- pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed packages\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only cell that you should have to make edits to.\n",
    "Enter in your desired input and output file paths \n",
    "and change what you deem to be an acceptable recovery range.\n",
    "*replaced .txt with /t separtaor with .csv with , separator*\n",
    "*should we implement both options? What will be used?*\n",
    "*New: indicate directory to save plots to*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data upload file path\n",
    "raw_filepath = r'example_data_raw\\PFAS_ACF_Batch1.csv'\n",
    "\n",
    "# file path for IDL and IQL data\n",
    "IDL_IQL_filepath = r'example_data_raw\\IDL_IQL.csv'\n",
    "\n",
    "# processed data output file path\n",
    "processed_filepath =r'example_data_processed\\PFAS_ACF_Batch1_processed.xlsx'\n",
    "\n",
    "# file path to write QCS0 data to \n",
    "qcs0_filepath = r'example_data_processed\\QCS0_area_values.csv'\n",
    "\n",
    "# directory to save plots to\n",
    "plot_directory = r'example_figures'\n",
    "\n",
    "#color-coding for recoveries table\n",
    "in_range = 'background-color: green'\n",
    "in_range_min_val = 0.6 \n",
    "in_range_max_val = 1.4\n",
    "out_range = 'background-color: red'\n",
    "out_range_min_val = 0.4 \n",
    "out_range_max_val = 1.8\n",
    "question_range = 'background-color: yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file and remove calibration data\n",
    "data = pd.read_csv(raw_filepath, delimiter=',', low_memory=False, header=0,)\n",
    "data_calibration_excluded = data[(data['Sample Type'] != 'Standard')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values of isotope dilution analysis (IDA) and save areas of intensity peaks to the variable ida_area\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area']\n",
    "ida_area = data_calibration_excluded[selected_columns_area]\n",
    "ida_area = ida_area[ida_area['Component Name'].str.contains('IDA')].copy()\n",
    "ida_area.loc[:,'Sample Name Date'] = ida_area['Sample Name'].astype(str) + \"_\" + ida_area['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "ida_area_piv = ida_area.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following file extracts quality control standard data (QSC0) from the isotope dilution analaysis (IDA) \n",
    "# and appends it to an excisting QCS0 file which is indicated in the second code block\n",
    "# (*qcs0_filepath*).\n",
    "\n",
    "# Filter rows where 'Sample Name' contains 'QCS0'\n",
    "qcs0_samples = ida_area_piv.reset_index()\n",
    "qcs0_samples = qcs0_samples[qcs0_samples['Sample Name Date'].str.contains('QCS0')]\n",
    "\n",
    "# Append the filtered DataFrame to an existing CSV file\n",
    "if os.path.exists(qcs0_filepath):\n",
    "    # Load the existing data\n",
    "    qsc0_existing_data = pd.read_csv(qcs0_filepath)\n",
    "    \n",
    "    # Combine existing data with new data, avoiding duplicates\n",
    "    qsc0_combined_data = pd.concat([qsc0_existing_data, qcs0_samples]).drop_duplicates(subset=['Sample Name Date'])\n",
    "    \n",
    "    # Write back to the CSV without writing headers again\n",
    "    qsc0_combined_data.to_csv(qcs0_filepath, index=False)\n",
    "else:\n",
    "    # If the file doesn't exist, write the data with headers\n",
    "    qcs0_samples.to_csv(qcs0_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of recovery rates: for each IDA row take area and divide it by average area of QCS0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recoveries\n",
    "# Average QCS0 from saved csv file\n",
    "qsc0_combined_data=pd.read_csv(qcs0_filepath, header=0, low_memory=False)\n",
    "qsc0_combined_data.drop(columns=['Sample Name Date'], inplace=True)\n",
    "qsc0_avg = qsc0_combined_data.mean()\n",
    "\n",
    "# Generate base of recovery table by copying the area pivot data\n",
    "recovery = ida_area_piv.copy()\n",
    "\n",
    "# Recovery calculation (sample area/avg QCS0 area)\n",
    "for index, row in ida_area_piv.iterrows():\n",
    "    for col in ida_area_piv.columns:\n",
    "        if ida_area_piv[col].dtype in ['float64', 'int64']:\n",
    "            recovery.at[index, col] = row[col] / qsc0_avg[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\897188779.py:11: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_recovery = recovery.style.applymap(color_map)\n"
     ]
    }
   ],
   "source": [
    "# color code recoveries\n",
    "def color_map(val):\n",
    "    if in_range_min_val <= val <= in_range_max_val:\n",
    "        return in_range\n",
    "    elif val < out_range_min_val or val > out_range_max_val:\n",
    "        return out_range\n",
    "    else:\n",
    "        return question_range\n",
    "\n",
    "# Apply the style function to the entire DataFrame\n",
    "styled_recovery = recovery.style.applymap(color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute method detection limits based on avaerage and standard deviation of process blanks. Use instrument detection limits (IDL) for the PFAS compounds not included in the process blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\3858484659.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  process_blank_data = process_blank_data.replace(\"<1 points\", np.nan)\n",
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\3858484659.py:21: RuntimeWarning: Mean of empty slice\n",
      "  process_blank_data_avg = np.nanmean(process_blank_data, axis=0)\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "\n",
    "# Isolate blank data and remove IDA/IPS values\n",
    "data_isolated_blank = data_calibration_excluded[data_calibration_excluded['Sample Comment'].str.contains('Blank')]\n",
    "data_isolated_blank = data_isolated_blank[selected_columns]\n",
    "data_isolated_blank = data_isolated_blank[~data_isolated_blank['Component Name'].str.contains('IDA|IPS')]\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column header, and concentration as the value\n",
    "blank_data_piv = data_isolated_blank.pivot_table(index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first')\n",
    "\n",
    "# Isolate the process blank data\n",
    "process_blank_data = blank_data_piv[blank_data_piv.index.str.contains('PB')]\n",
    "\n",
    "# replace all <1 point values with NaN values\n",
    "process_blank_data = process_blank_data.replace(\"<1 points\", np.nan)\n",
    "\n",
    "# Change any non numeric values to numeric\n",
    "process_blank_data = process_blank_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# calculate the average PB value excluding NaN values\n",
    "process_blank_data_avg = np.nanmean(process_blank_data, axis=0)\n",
    "process_blank_data.loc['PB_avg'] = process_blank_data_avg\n",
    "\n",
    "# calculate the standard deviation\n",
    "process_blank_data_stdev = process_blank_data.std(skipna=True)\n",
    "process_blank_data.loc['PB_stdev'] = process_blank_data_stdev\n",
    "\n",
    "# MDL calculation PB_avg + 3 * PB_stdev\n",
    "process_blank_data.loc['MDL'] = np.nan_to_num(process_blank_data.loc['PB_avg']) + 3 * np.nan_to_num(process_blank_data.loc['PB_stdev'])\n",
    "process_blank_data.loc['MDL'] = process_blank_data.loc['MDL'].replace(0, np.nan)\n",
    "\n",
    "#Load IDL_IQL file\n",
    "IDL_IQL = pd.read_csv(IDL_IQL_filepath, index_col=0, low_memory=False)\n",
    "\n",
    "#change all non numeric values to numeric\n",
    "IDL_IQL = IDL_IQL.apply(pd.to_numeric, errors='coerce')\n",
    "IQL = IDL_IQL.loc[['IQL']]  \n",
    "IQL = IQL.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#replace all NaN values in MDL with the IQL value\n",
    "common_columns = process_blank_data.columns.intersection(IQL.columns)\n",
    "process_blank_data.loc['MDL', common_columns] = process_blank_data.loc['MDL', common_columns].combine_first(IQL.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load concentration data and apply method detection limits (MDL) to filter values below MDL.\n",
    "Values below MDL are replaced with \\< MDL.\n",
    "\n",
    "Remark 1: mix of floats and strings.\n",
    "Remark 2: when calculation of concentration outputs NA, it is converted to \\< MDL, ist this really what we want to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\2190286193.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_blank_excluded_table = data_blank_excluded_table.replace(\"<1 points\", np.nan)\n"
     ]
    }
   ],
   "source": [
    "# Load concentration data and exclude blanks\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "data_blank_excluded = data_calibration_excluded[data_calibration_excluded['Sample Comment'] != 'Blank'][selected_columns].copy()\n",
    "data_blank_excluded = data_blank_excluded[~data_blank_excluded['Component Name'].str.contains('IDA|IPS')]\n",
    "# selects only columns available in QCS0 data\n",
    "data_blank_excluded_table = data_blank_excluded.copy().pivot_table(\n",
    "    index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first'\n",
    "    )\n",
    "data_blank_excluded_table = data_blank_excluded_table.replace(\"<1 points\", np.nan)\n",
    "\n",
    "# Align the columns of PB with data_without_blank\n",
    "common_columns = data_blank_excluded_table.columns.intersection(process_blank_data.columns)\n",
    "PB_aligned = process_blank_data[common_columns]\n",
    "\n",
    "# Convert MDL values to numeric to handle both numeric and string types\n",
    "mdl_values = pd.to_numeric(PB_aligned.loc['MDL'], errors='coerce')\n",
    "\n",
    "# Use np.where with numeric comparison\n",
    "data_blank_excluded_table[common_columns] = np.where(\n",
    "    data_blank_excluded_table[common_columns].apply(pd.to_numeric, errors='coerce') < mdl_values.values,\n",
    "    \"<MDL\", data_blank_excluded_table[common_columns]\n",
    "    )\n",
    "data_blank_excluded_table = data_blank_excluded_table.fillna('<MDL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13C3_PFBA_TOF MS', '13C4_PFBA_TOF MS', '13C5_PFPeA_TOF MS', '13C5_PFHxA_TOF MS', '13C4_PFHpA_TOF MS', '13C2_PFOA_TOF MS', '13C8_PFOA_TOF MS', '13C9_PFNA_TOF MS', '13C6_PFDA_TOF MS', '13C7_PFUdA_TOF MS', '13C2_PFDoA_TOF MS', '13C2_PFTeDA_TOF MS', '13C3_PFBS_TOF MS', '13C3_PFHxS_TOF MS', '13C4_PFOS_TOF MS', '13C8_PFOS_TOF MS', '13C8_FOSA_TOF MS', 'd3-MeFOSAA_TOF MS', 'd5-EtFOSAA_TOF MS', 'd-MeFOSA_TOF MS', 'd-EtFOSA_TOF MS', '13C3_HFPO-DA_TOF MS', '13C2 4:2 FTS_TOF MS', '13C2 6:2 FTS_TOF MS', '13C2 8:2 FTS_TOF MS'] are lost\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\1104645854.py:32: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  concentration_table_default_np = concentration_table_default.replace(\n",
      "C:\\Users\\johanna.ganglbauer\\AppData\\Local\\Temp\\ipykernel_20496\\1104645854.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  concentration_table_tof_np = concentration_table_tof.replace(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(1, 52, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[202], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39msubtract(concentration_table_default_np, concentration_table_tof_np)\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m     39\u001b[0m ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msubtract(concentration_table_default_np, concentration_table_tof_np) \\\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39madd(concentration_table_default_np, concentration_table_tof_np),\n\u001b[1;32m---> 41\u001b[0m concentration_table_ratio \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentration_table_default\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentration_table_default\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(concentration_table_ratio)\n",
      "File \u001b[1;32mc:\\Users\\johanna.ganglbauer\\AppData\\Local\\anaconda3\\envs\\lohmann\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m             arrays,\n\u001b[0;32m    861\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m         {},\n\u001b[0;32m    878\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johanna.ganglbauer\\AppData\\Local\\anaconda3\\envs\\lohmann\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[0;32m    324\u001b[0m         values,\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johanna.ganglbauer\\AppData\\Local\\anaconda3\\envs\\lohmann\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:582\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     values \u001b[38;5;241m=\u001b[39m convert(values)\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johanna.ganglbauer\\AppData\\Local\\anaconda3\\envs\\lohmann\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(1, 52, 50)"
     ]
    }
   ],
   "source": [
    "# correct channel names in original data (all of the TOF channels are labelled by _TOF MS, only 2 of them are labeled by only _TOF)\n",
    "mask_names = data_blank_excluded['Component Name'].str.endswith('_TOF')\n",
    "data_blank_excluded['Component Name'][mask_names] = [compound + ' MS' for compound in data_blank_excluded['Component Name'][mask_names].to_list()]\n",
    "\n",
    "# get list of all compounds\n",
    "compounds_list = data_blank_excluded['Component Name'].value_counts().index.to_list()\n",
    "\n",
    "# sort compounds by channels\n",
    "compounds_list_channel_tof = [compound for compound in compounds_list if '_TOF MS' in compound]\n",
    "compounds_list_channel_default = [compound for compound in compounds_list if '_TOF MS' not in compound]\n",
    "\n",
    "# try to assign TOF channel_name to each default channel name and keep record of TOF channel values lost in the process\n",
    "compounds_sorted_default = []\n",
    "compounds_sorted_tof = []\n",
    "for compound in compounds_list_channel_default:\n",
    "    if compound + '_TOF MS' in compounds_list_channel_tof:\n",
    "        compounds_sorted_default.append(compound)\n",
    "        compounds_sorted_tof.append(compound + '_TOF MS')\n",
    "    else:\n",
    "        print(f'{compound} is lost')\n",
    "\n",
    "print(f'{[compound for compound in compounds_list_channel_tof if compound not in compounds_sorted_tof]} are lost')\n",
    "mapper = {old_name: new_name for (old_name, new_name) in zip(compounds_sorted_tof, compounds_sorted_default)}\n",
    "\n",
    "# create table with sample name as row, compound as header and calculated concentration as value for default channel\n",
    "concentration_table_all = data_blank_excluded.pivot_table(\n",
    "    values='Calculated Concentration', index=['Sample Name'], columns=['Component Name'], aggfunc='first', dropna=False\n",
    "    )\n",
    "concentration_table_default = concentration_table_all[compounds_sorted_default]\n",
    "concentration_table_tof = concentration_table_all[compounds_sorted_tof]\n",
    "\n",
    "concentration_table_default_np = concentration_table_default.replace(\n",
    "    {'<1 points': np.nan, '< 0': np.nan, 'no root': np.nan, None: np.nan, }\n",
    "    ).to_numpy().astype(float)\n",
    "concentration_table_tof_np = concentration_table_tof.replace(\n",
    "    {'<1 points': np.nan, '< 0': np.nan, 'no root': np.nan, None: np.nan, }\n",
    "    ).to_numpy().astype(float)\n",
    "print(np.subtract(concentration_table_default_np, concentration_table_tof_np).ndim)\n",
    "ratio = np.divide(\n",
    "    200 * np.subtract(concentration_table_default_np, concentration_table_tof_np),\n",
    "    np.add(concentration_table_default_np, concentration_table_tof_np),\n",
    "    )\n",
    "concentration_table_ratio = pd.DataFrame(\n",
    "    ratio, index=concentration_table_default.index, columns=concentration_table_default.columns,\n",
    "    )\n",
    "print(concentration_table_ratio)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine linear calibration curve based on calibration data.\n",
    "*to be discussed: method for R2 computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sanitize file names\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Removes special characters from PFAS name to create valid directory names.\"\"\"    \n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)\n",
    "\n",
    "# extract PFAS data\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Actual Concentration','IS Actual Concentration','Area','IS Area']\n",
    "data_pfas = data[data['Sample Name'].str.contains('PFAS CS')].copy()\n",
    "data_pfas = data_pfas.fillna(0)\n",
    "data_pfas = data_pfas[~data_pfas['Component Name'].str.contains('IDA|IPS|13C|d3|d5')]\n",
    "data_pfas_ = data_pfas[~data_pfas['Component Name'].str.contains('TOF')]\n",
    "data_pfas_['Concentration/IS Concentration'] = data_pfas_['Actual Concentration']/data_pfas_['IS Actual Concentration']\n",
    "data_pfas_['Area/IS Area'] = data_pfas_['Area']/data_pfas_['IS Area']\n",
    "\n",
    "# Create a list of unique sample names and count them.\n",
    "components = data_pfas_['Component Name'].unique()\n",
    "n_components = len(components)\n",
    "\n",
    "image_paths = []\n",
    "# Iterate over each component and create scatter plots with regression lines\n",
    "for i, component in enumerate(components):\n",
    "    component_data = data_pfas_[data_pfas_['Component Name'] == component]\n",
    "    \n",
    "    # Extract x and y values\n",
    "    x = component_data['Concentration/IS Concentration'].values.reshape(-1, 1)\n",
    "    y = component_data['Area/IS Area'].values\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # Regression equation\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "\n",
    "    plt.figure(figsize = (8,6))\n",
    "    # Plot with Seaborn\n",
    "    sns.regplot(\n",
    "       # ax=axes[i], \n",
    "        x=x.flatten(), \n",
    "        y=y, \n",
    "        scatter=True, \n",
    "        fit_reg=True,\n",
    "        line_kws={\"color\": \"red\"},  # Color of the regression line\n",
    "        scatter_kws={\"s\": 50, \"alpha\": 0.7},  # Customize scatter points\n",
    "        ci=95\n",
    "    )\n",
    "    # Set the title with the component name\n",
    "    plt.title(f'{component}')\n",
    "    plt.xlabel('Concentration/IS Concentration')\n",
    "    plt.ylabel('Area/IS Area')\n",
    "    plt.text(0.05, 0.95, f'{equation}\\n$R^2$ = {r2:.2f}', \n",
    "             transform=plt.gca().transAxes, \n",
    "             fontsize=10, \n",
    "             verticalalignment='top', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "   \n",
    "    # Sanitize the file name\n",
    "    sanitized_component = sanitize_filename(component)\n",
    "    image_path = os.path.join(plot_directory, f'{sanitized_component}.png')\n",
    "    \n",
    "    # Save the plot as an image\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "    \n",
    "    image_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes all relevant data to excel file and adds calibration curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create excel with pandas excelwriter\n",
    "with pd.ExcelWriter(processed_filepath, engine='openpyxl') as writer:\n",
    "    styled_recovery.to_excel(writer, sheet_name='Recoveries')\n",
    "    process_blank_data.to_excel(writer, sheet_name='MDL_Values')\n",
    "    data_blank_excluded_table.to_excel(writer, sheet_name='Concentration_filtered_MDL')\n",
    "    ida_area_piv.to_excel(writer, sheet_name='Area_Pivot')\n",
    "    IDL_IQL.to_excel(writer, sheet_name='IDL_IQL')\n",
    "    data_pfas_.to_excel(writer, sheet_name='Calibration Data')\n",
    "    concentration_table_default.to_excel(writer, sheet_name='Calculated concentration')\n",
    "    concentration_table_tof.to_excel(writer, sheet_name='TOF Calculated concentration')\n",
    "    concentration_table_ratio.to_excel(writer, sheet_name='Calculated concentration Percentage Difference')\n",
    "\n",
    "workbook = load_workbook(processed_filepath)\n",
    "plot_sheet = workbook.create_sheet('Calibration Curves')\n",
    "    \n",
    "# Insert all images into one sheet in a grid format\n",
    "row_offset = 1  # Start at the first row\n",
    "col_offset = 1  # Start at the first column\n",
    "images_per_row = 2  # Number of images per row\n",
    "\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # Calculate the position for each image\n",
    "    row_position = row_offset + (i // images_per_row) * 15  # Adjust the multiplier to control spacing\n",
    "    col_position = col_offset + (i % images_per_row) * 20   # Adjust the multiplier to control spacing\n",
    "    \n",
    "    # Load the image\n",
    "    img = Image(image_path)\n",
    "    \n",
    "    # Place the image at the calculated position\n",
    "    cell_position = plot_sheet.cell(row=row_position, column=col_position).coordinate\n",
    "    plot_sheet.add_image(img, cell_position)\n",
    "\n",
    "workbook.save(processed_filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

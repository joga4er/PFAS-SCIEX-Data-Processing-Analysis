{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is the only cell that you should have to make edits to, enter in your desired input and output file paths and change what you deem to be an acceptable recovery range\n",
    "#raw data upload file path\n",
    "raw_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\Raw_Data\\PFAS_ACF_Batch1.txt'\n",
    "\n",
    "#processed data output file path\n",
    "processed_filepath =r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\Processed_Data\\PFAS_ACF_Batch1_processed.xlsx'\n",
    "\n",
    "#file path to write QCS0 data to \n",
    "qcs0_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\QCS0_area_values\\QCS0_area_values.csv' \n",
    "\n",
    "#file path for IDL and IQL data\n",
    "IDL_IQL_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\ACF\\IDL_IQL.csv'\n",
    "\n",
    "#color-coding for recoveries table\n",
    "in_range = 'background-color: green'\n",
    "in_range_min_val = 0.6 \n",
    "in_range_max_val = 1.4\n",
    "out_range = 'background-color: red'\n",
    "out_range_min_val = 0.4 \n",
    "out_range_max_val = 1.8\n",
    "question_range = 'background-color: yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "wb= Workbook()\n",
    "ws=wb.active\n",
    "\n",
    "#Load data file\n",
    "df=pd.read_csv(raw_filepath, delimiter='\\t', low_memory=False)\n",
    "\n",
    "#remove Calibtration data\n",
    "df1 = df[df['Sample Type'] != 'Standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out all but IDA area values for recovery calculation\n",
    "selected_columns = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area']\n",
    "area=df1[selected_columns]\n",
    "area_ida = area[area['Component Name'].str.contains('IDA')].copy()\n",
    "area_ida.loc[:,'Sample Name Date'] = area_ida['Sample Name'].astype(str) + \"_\" + area_ida['Acquisition Date & Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "area_piv = area_ida.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Sample Name' contains 'QCS0'\n",
    "qcs0_samples = area_piv.reset_index()\n",
    "qcs0_samples = qcs0_samples[qcs0_samples['Sample Name Date'].str.contains('QCS0')]\n",
    "\n",
    "# Append the filtered DataFrame to an existing CSV file\n",
    "if os.path.exists(qcs0_filepath):\n",
    "    # Load the existing data\n",
    "    existing_data = pd.read_csv(qcs0_filepath)\n",
    "    \n",
    "    # Combine existing data with new data, avoiding duplicates\n",
    "    combined_data = pd.concat([existing_data, qcs0_samples]).drop_duplicates(subset=['Sample Name Date'])\n",
    "    \n",
    "    # Write back to the CSV without writing headers again\n",
    "    combined_data.to_csv(qcs0_filepath, index=False)\n",
    "else:\n",
    "    # If the file doesn't exist, write the data with headers\n",
    "    qcs0_samples.to_csv(qcs0_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Recoveries\n",
    "#Average QCS0 from saved csv file\n",
    "QCS0=pd.read_csv(qcs0_filepath, low_memory=False)\n",
    "\n",
    "#QCS0 averages\n",
    "avg_QCS0 = QCS0.mean().to_frame(name='Average').T\n",
    "\n",
    "#Generate base of recovery table by copying the area pivot data\n",
    "recovery= area_piv.copy()\n",
    "\n",
    "# Recovery calculation (sample area/avg QCS0 area)\n",
    "for index, row in area_piv.iterrows():\n",
    "    for col in area_piv.columns:\n",
    "        if area_piv[col].dtype in ['float64', 'int64']:\n",
    "            recovery.at[index, col] = row[col] / avg_QCS0[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color code recoveries\n",
    "def color_map(val):\n",
    "    if in_range_min_val <= val <= in_range_max_val:\n",
    "        return in_range\n",
    "    elif val < out_range_min_val or val > out_range_max_val:\n",
    "        return out_range\n",
    "    else:\n",
    "        return question_range\n",
    "\n",
    "    # Apply the style function to the entire DataFrame\n",
    "styled_recovery = recovery.style.applymap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhsan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "##MDL\n",
    "#Load concentration data\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "\n",
    "#Isolate blank data\n",
    "df2 = df1[df1['Sample Comment'].str.contains('Blank')]\n",
    "df2 = df2[selected_columns]\n",
    "\n",
    "#Remove any IDA or IPS values\n",
    "df2 = df2[~df2['Component Name'].str.contains('IDA|IPS')]\n",
    "\n",
    "#Create pivot table with Sample name as the index, component name as the column header, and concentration as the value\n",
    "df2_piv = df2.pivot_table(index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first')\n",
    "\n",
    "#Isolate the process blank data\n",
    "PB = df2_piv[df2_piv.index.str.contains('PB')]\n",
    "\n",
    "#replace all <1point values with NaN values\n",
    "PB= PB.replace(\"<1 points\", np.nan)\n",
    "\n",
    "#Change any non numeric valeus to numeric\n",
    "PB=PB.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#calculate the average PB value excluding NaN values\n",
    "PB_avg = np.nanmean(PB, axis=0)\n",
    "#create a row called PB_avg\n",
    "PB.loc['PB_avg'] = PB_avg\n",
    "\n",
    "#calculate the standard deviation\n",
    "PB_stdev = PB.std(skipna=True)\n",
    "PB.loc['PB_stdev'] = PB_stdev\n",
    "\n",
    "#MDL calculation PB_avg + 3*PB_stdev\n",
    "PB.loc['MDL']=np.nan_to_num(PB.loc['PB_avg'])+ 3*np.nan_to_num(PB.loc['PB_stdev'])\n",
    "PB.loc['MDL']=PB.loc['MDL'].replace(0, np.nan)\n",
    "\n",
    "#Load IDL_IQL file\n",
    "IDL_IQL = pd.read_csv(IDL_IQL_filepath, index_col=0, low_memory=False)\n",
    "\n",
    "#change all non numeric values to numeric\n",
    "IDL_IQL = IDL_IQL.apply(pd.to_numeric, errors='coerce')\n",
    "IQL = IDL_IQL.loc[['IQL']]  \n",
    "IQL = IQL.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#replace all NaN values in MDL with the IQL value\n",
    "common_columns = PB.columns.intersection(IQL.columns)\n",
    "PB.loc['MDL', common_columns] = PB.loc['MDL', common_columns].combine_first(IQL.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load concentration data\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "df3=df1[df1['Sample Comment'] != 'Blank'][selected_columns].copy()\n",
    "df3 = df3[~df3['Component Name'].str.contains('IDA|IPS')]\n",
    "df3 = df3.pivot_table(index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first')\n",
    "df3= df3.replace(\"<1 points\", np.nan)\n",
    "\n",
    "# Align the columns of PB with df3\n",
    "common_columns = df3.columns.intersection(PB.columns)\n",
    "PB_aligned = PB[common_columns]\n",
    "\n",
    "# Replace values in df3 that are less than MDL with '<MDL'\n",
    "mdl_df = pd.DataFrame('<MDL', index=df3.index, columns=common_columns)\n",
    "\n",
    "# Convert MDL values to numeric to handle both numeric and string types\n",
    "mdl_values = pd.to_numeric(PB_aligned.loc['MDL'], errors='coerce')\n",
    "\n",
    "# Use np.where with numeric comparison\n",
    "df3[common_columns] = np.where(df3[common_columns].apply(pd.to_numeric, errors='coerce') < mdl_values.values, mdl_df, df3[common_columns])\n",
    "#change all NaN to <MDL\n",
    "df3 = df3.fillna('<MDL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Sample Name', 'Component Name', 'Actual Concentration','IS Actual Concentration','Area','IS Area']\n",
    "df4=df[df['Sample Name'].str.contains('PFAS CS')].copy()\n",
    "df4 = df4.fillna(0)\n",
    "df4 = df4[~df4['Component Name'].str.contains('IDA|IPS|13C|d3|d5|TOF')]\n",
    "df4['Concentration/IS Concentration']=df4['Actual Concentration']/df4['IS Actual Concentration']\n",
    "df4['Area/IS Area']=df4['Area']/df4['IS Area']\n",
    "df4\n",
    "# Create a list of unique sample names\n",
    "components = df4['Component Name'].unique()\n",
    "n_components = len(components)\n",
    "#create single plot\n",
    "#fig, axes = plt.subplots(n_components, 1, sharex=True, figsize = (8, n_components * 3))\n",
    "cal_dir = tempfile.mkdtemp()\n",
    "# Function to sanitize file names\n",
    "def sanitize_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)\n",
    "image_paths = []\n",
    "# Iterate over each component and create scatter plots with regression lines\n",
    "for i, component in enumerate(components):\n",
    "    component_data = df4[df4['Component Name'] == component]\n",
    "    \n",
    "    # Extract x and y values\n",
    "    x = component_data['Concentration/IS Concentration'].values.reshape(-1, 1)\n",
    "    y = component_data['Area/IS Area'].values\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "# Regression equation\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "    plt.figure(figsize = (8,6))\n",
    "    # Plot with Seaborn\n",
    "    sns.regplot(\n",
    "       # ax=axes[i], \n",
    "        x=x.flatten(), \n",
    "        y=y, \n",
    "        scatter=True, \n",
    "        fit_reg=True,\n",
    "        line_kws={\"color\": \"red\"},  # Color of the regression line\n",
    "        scatter_kws={\"s\": 50, \"alpha\": 0.7},  # Customize scatter points\n",
    "        ci=95\n",
    "    )\n",
    "    # Set the title with the component name\n",
    "    plt.title(f'{component}')\n",
    "    plt.xlabel('Concentration/IS Concentration')\n",
    "    plt.ylabel('Area/IS Area')\n",
    "    plt.text(0.05, 0.95, f'{equation}\\n$R^2$ = {r2:.2f}', \n",
    "             transform=plt.gca().transAxes, \n",
    "             fontsize=10, \n",
    "             verticalalignment='top', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "   \n",
    "    # Sanitize the file name\n",
    "    sanitized_component = sanitize_filename(component)\n",
    "    image_path = os.path.join(cal_dir, f'{sanitized_component}.png')\n",
    "    \n",
    "    # Save the plot as an image\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "    \n",
    "    image_paths.append(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to worksheets in same workbook\n",
    "with pd.ExcelWriter(processed_filepath, engine = 'openpyxl') as writer:\n",
    "    writer.book = wb\n",
    "    writer.sheets = dict((ws.title, ws)for ws in wb.worksheets)\n",
    "    styled_recovery.to_excel(writer, sheet_name = 'Recoveries')\n",
    "    PB.to_excel(writer, sheet_name = 'MDL_Values')\n",
    "    df3.to_excel(writer, sheet_name = 'Concentration_filtered_MDL')\n",
    "    area_piv.to_excel(writer, sheet_name = \"Area_Pivot\")\n",
    "    IDL_IQL.to_excel(writer, sheet_name = \"IDL_IQL\")\n",
    "    df4.to_excel(writer, sheet_name = \"Calibration Data\")\n",
    "    # Saved Calibration graphs\n",
    "    sheet_name = 'Calibration Curves'\n",
    "    if sheet_name not in writer.sheets:\n",
    "        writer.book.create_sheet(sheet_name)\n",
    "    worksheet = writer.book[sheet_name]\n",
    "    \n",
    "    # Insert all images into one sheet in a grid format\n",
    "    row_offset = 1  # Start at the first row\n",
    "    col_offset = 1  # Start at the first column\n",
    "    images_per_row = 2  # Number of images per row\n",
    "\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        # Calculate the position for each image\n",
    "        row_position = row_offset + (i // images_per_row) * 20  # Adjust the multiplier to control spacing\n",
    "        col_position = col_offset + (i % images_per_row) * 10   # Adjust the multiplier to control spacing\n",
    "        \n",
    "        # Load the image\n",
    "        img = Image(image_path)\n",
    "        \n",
    "        # Place the image at the calculated position\n",
    "        cell_position = worksheet.cell(row=row_position, column=col_position).coordinate\n",
    "        worksheet.add_image(img, cell_position)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name: lcms_data_processing\n",
    "date: 08/20/2024\n",
    "version: 1.0\n",
    "author: Justin Sankey\n",
    "\n",
    "description: Takes raw liquit chromatography mass spectroscopy (LCMS) data, \n",
    "extracts relevant paramters for analysis and writes them to excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute the notebook for the first time you need to install all required python packages.\n",
    "So, type the following commands in your python console or anaconda prompt:\n",
    "- pip install pandas\n",
    "- pip install numpy\n",
    "- pip install matplotlib\n",
    "- pip install seaborn\n",
    "- pip install scikit-learn\n",
    "- pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed packages\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the only cell that you should have to make edits to.\n",
    "Enter in your desired input and output file paths \n",
    "and change what you deem to be an acceptable recovery range.\n",
    "*replaced .txt with /t separtaor with .csv with , separator*\n",
    "*should we implement both options? What will be used?*\n",
    "*New: indicate directory to save plots to*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data upload file path\n",
    "raw_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\Raw_Data\\20240903_pfas_kynol_ks_single_compound.csv'\n",
    "# file path for IDL and IQL data\n",
    "IDL_IQL_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\ACF\\IDL_IQL.csv'\n",
    "\n",
    "# processed data output file path\n",
    "processed_filepath =r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\Processed_Data\\20240903_pfas_kynol_ks_single_compound_processed.xlsx'\n",
    "\n",
    "# file path to write QCS0 data to \n",
    "qcs0_filepath = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\QCS0_area_values\\QCS0_area_values.csv' \n",
    "\n",
    "# directory to save plots to\n",
    "plot_directory = r'C:\\Users\\jhsan\\OneDrive\\Desktop\\ACF_Project\\Processed_Data\\Plots'\n",
    "\n",
    "#color-coding for recoveries table\n",
    "in_range = 'background-color: green'\n",
    "in_range_min_val = 0.6 \n",
    "in_range_max_val = 1.4\n",
    "out_range = 'background-color: red'\n",
    "out_range_min_val = 0.4 \n",
    "out_range_max_val = 1.8\n",
    "question_range = 'background-color: yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file and remove calibration data\n",
    "data = pd.read_csv(raw_filepath, delimiter=',', low_memory=False, header=0,)\n",
    "data_calibration_excluded = data[(data['Sample Type'] != 'Standard')].copy()\n",
    "data_calibration = data[data['Sample Type']=='Standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values of isotope dilution analysis (IDA) and save areas of intensity peaks to the variable ida_area\n",
    "#selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area']\n",
    "#ida_area = data_calibration_excluded[selected_columns_area]\n",
    "#ida_area = ida_area[ida_area['Component Name'].str.contains('IDA')].copy()\n",
    "#ida_area.loc[:,'Sample Name Date'] = ida_area['Sample Name'].astype(str) + \"_\" + ida_area['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "#ida_area_piv = ida_area.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area IDA values for IDA components\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area IDA']\n",
    "area_ida = data_calibration_excluded[selected_columns_area]\n",
    "area_ida = area_ida[area_ida['Component Name'].str.contains('IDA')]\n",
    "area_ida.loc[:,'Sample Name Date'] = area_ida['Sample Name'].astype(str) + \"_\" + area_ida['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "area_ida_piv = area_ida.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area IDA', aggfunc='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration Area IDA Average for IDA components\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area IDA']\n",
    "cal_area_ida = data_calibration[selected_columns_area]\n",
    "cal_area_ida = cal_area_ida[cal_area_ida['Component Name'].str.contains('IDA')]\n",
    "cal_area_ida.loc[:,'Sample Name Date'] = cal_area_ida['Sample Name'].astype(str) + \"_\" + cal_area_ida['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "cal_area_ida_piv = cal_area_ida.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area IDA', aggfunc='first')\n",
    "#Establishes a row with average of each column\n",
    "mean_cal = cal_area_ida_piv.mean(numeric_only=True)\n",
    "mean_cal=pd.DataFrame(mean_cal).T\n",
    "mean_cal.index=['Average']\n",
    "cal_area_ida_piv = pd.concat([cal_area_ida_piv,mean_cal])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPS Area Values for IDA components\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area IPS']\n",
    "area_ips = data_calibration_excluded[selected_columns_area]\n",
    "area_ips = area_ips[area_ips['Component Name'].str.contains('IDA')]\n",
    "area_ips.loc[:,'Sample Name Date'] = area_ips['Sample Name'].astype(str) + \"_\" + area_ips['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "area_ips_piv = area_ips.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area IPS', aggfunc='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPS Calibration Area and Average for IDA components\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Area IPS']\n",
    "cal_area_ips = data_calibration[selected_columns_area]\n",
    "cal_area_ips = cal_area_ips[cal_area_ips['Component Name'].str.contains('IDA')]\n",
    "cal_area_ips.loc[:,'Sample Name Date'] = cal_area_ips['Sample Name'].astype(str) + \"_\" + cal_area_ida['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "cal_area_ips_piv = cal_area_ips.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Area IPS', aggfunc='first')\n",
    "#establishes mean for each column\n",
    "mean_cal = cal_area_ips_piv.mean(numeric_only=True)\n",
    "mean_cal=pd.DataFrame(mean_cal).T\n",
    "mean_cal.index=['Average']\n",
    "cal_area_ips_piv = pd.concat([cal_area_ips_piv,mean_cal])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration IDA/IPS ratio\n",
    "cal_ida_ips_ratio = cal_area_ida_piv.loc['Average']/cal_area_ips_piv.loc['Average']\n",
    "cal_ida_ips_ratio\n",
    "#Sample IDA/IPS Ratio\n",
    "sample_ida_ips_ratio = area_ida_piv/area_ips_piv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPS normalized recoveries to calibration data\n",
    "ips_norm_recovery = sample_ida_ips_ratio/cal_ida_ips_ratio\n",
    "ips_norm_recovery\n",
    "# color code recoveries\n",
    "def color_map(val):\n",
    "    if in_range_min_val <= val <= in_range_max_val:\n",
    "        return in_range\n",
    "    elif val < out_range_min_val or val > out_range_max_val:\n",
    "        return out_range\n",
    "    else:\n",
    "        return question_range\n",
    "\n",
    "# Apply the style function to the entire DataFrame\n",
    "styled_ips_norm_recovery = ips_norm_recovery.style.applymap(color_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reported Recovery Pivot Table\n",
    "selected_columns_area = ['Sample Name', 'Sample Index','Acquisition Date & Time','Component Name', 'Reported Recovery']\n",
    "reported_recovery = data_calibration_excluded[selected_columns_area]\n",
    "reported_recovery = reported_recovery[reported_recovery['Component Name'].str.contains('IDA')]\n",
    "reported_recovery.loc[:,'Sample Name Date'] = reported_recovery['Sample Name'].astype(str) + \"_\" + reported_recovery['Acquisition Date & Time']\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column headers, and area as the values\n",
    "reported_recovery_piv = reported_recovery.pivot_table(index=('Sample Name Date',), columns='Component Name', values='Reported Recovery', aggfunc='first')\n",
    "reported_recovery_piv=reported_recovery_piv/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color map of Reported recoveries\n",
    "styled_reported_recovery = reported_recovery_piv.style.applymap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following file extracts quality control standard data (QSC0) from the isotope dilution analaysis (IDA) \n",
    "# and appends it to an excisting QCS0 file which is indicated in the second code block\n",
    "# (*qcs0_filepath*).\n",
    "\n",
    "# Filter rows where 'Sample Name' contains 'QCS0'\n",
    "#qcs0_samples = ida_area_piv.reset_index()\n",
    "#qcs0_samples = qcs0_samples[qcs0_samples['Sample Name Date'].str.contains('QCS0')]\n",
    "\n",
    "# Append the filtered DataFrame to an existing CSV file\n",
    "#if os.path.exists(qcs0_filepath):\n",
    "    # Load the existing data\n",
    "   # qsc0_existing_data = pd.read_csv(qcs0_filepath)\n",
    "    \n",
    "    # Combine existing data with new data, avoiding duplicates\n",
    "    #qsc0_combined_data = pd.concat([qsc0_existing_data, qcs0_samples]).drop_duplicates(subset=['Sample Name Date'])\n",
    "    \n",
    "    # Write back to the CSV without writing headers again\n",
    "    #qsc0_combined_data.to_csv(qcs0_filepath, index=False)\n",
    "#else:\n",
    "    # If the file doesn't exist, write the data with headers\n",
    "    #qcs0_samples.to_csv(qcs0_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of recovery rates: for each IDA row take area and divide it by average area of QCS0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recoveries\n",
    "# Average QCS0 from saved csv file\n",
    "#qsc0_combined_data=pd.read_csv(qcs0_filepath, header=0, low_memory=False)\n",
    "#qsc0_combined_data.drop(columns=['Sample Name Date'], inplace=True)\n",
    "#qsc0_avg = qsc0_combined_data.mean()\n",
    "\n",
    "# Generate base of recovery table by copying the area pivot data\n",
    "#recovery = ida_area_piv.copy()\n",
    "\n",
    "# Recovery calculation (sample area/avg QCS0 area)\n",
    "#for index, row in ida_area_piv.iterrows():\n",
    "    #for col in ida_area_piv.columns:\n",
    "       # if ida_area_piv[col].dtype in ['float64', 'int64']:\n",
    "           # recovery.at[index, col] = row[col] / qsc0_avg[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color code recoveries\n",
    "#def color_map(val):\n",
    "    #if in_range_min_val <= val <= in_range_max_val:\n",
    "        #return in_range\n",
    "    #elif val < out_range_min_val or val > out_range_max_val:\n",
    "        #return out_range\n",
    "    #else:\n",
    "        #return question_range\n",
    "\n",
    "# Apply the style function to the entire DataFrame\n",
    "#styled_recovery = recovery.style.applymap(color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute method detection limits based on avaerage and standard deviation of process blanks. Use instrument detection limits (IDL) for the PFAS compounds not included in the process blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhsan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "\n",
    "# Isolate blank data and remove IDA/IPS values\n",
    "data_isolated_blank = data_calibration_excluded[data_calibration_excluded['Sample Comment'].str.contains('Blank')]\n",
    "data_isolated_blank = data_isolated_blank[selected_columns]\n",
    "data_isolated_blank = data_isolated_blank[~data_isolated_blank['Component Name'].str.contains('IDA|IPS')]\n",
    "\n",
    "# Create pivot table with Sample name as the index, component name as the column header, and concentration as the value\n",
    "blank_data_piv = data_isolated_blank.pivot_table(index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first')\n",
    "\n",
    "# Isolate the process blank data\n",
    "process_blank_data = blank_data_piv[blank_data_piv.index.str.contains('PB')]\n",
    "\n",
    "# replace all <1 point values with NaN values\n",
    "process_blank_data = process_blank_data.replace(\"<1 points\", np.nan)\n",
    "\n",
    "# Change any non numeric values to numeric\n",
    "process_blank_data = process_blank_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# calculate the average PB value excluding NaN values\n",
    "process_blank_data_avg = np.nanmean(process_blank_data, axis=0)\n",
    "process_blank_data.loc['PB_avg'] = process_blank_data_avg\n",
    "\n",
    "# calculate the standard deviation\n",
    "process_blank_data_stdev = process_blank_data.std(skipna=True)\n",
    "process_blank_data.loc['PB_stdev'] = process_blank_data_stdev\n",
    "\n",
    "# MDL calculation PB_avg + 3 * PB_stdev\n",
    "process_blank_data.loc['MDL'] = np.nan_to_num(process_blank_data.loc['PB_avg']) + 3 * np.nan_to_num(process_blank_data.loc['PB_stdev'])\n",
    "process_blank_data.loc['MDL'] = process_blank_data.loc['MDL'].replace(0, np.nan)\n",
    "\n",
    "#Load IDL_IQL file\n",
    "IDL_IQL = pd.read_csv(IDL_IQL_filepath, index_col=0, low_memory=False)\n",
    "\n",
    "#change all non numeric values to numeric\n",
    "IDL_IQL = IDL_IQL.apply(pd.to_numeric, errors='coerce')\n",
    "IQL = IDL_IQL.loc[['IQL']]  \n",
    "IQL = IQL.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#replace all NaN values in MDL with the IQL value\n",
    "common_columns = process_blank_data.columns.intersection(IQL.columns)\n",
    "process_blank_data.loc['MDL', common_columns] = process_blank_data.loc['MDL', common_columns].combine_first(IQL.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load concentration data and apply method detection limits (MDL) to filter values below MDL.\n",
    "Values below MDL are replaced with \\< MDL.\n",
    "\n",
    "Remark 1: mix of floats and strings.\n",
    "Remark 2: when calculation of concentration outputs NA, it is converted to \\< MDL, ist this really what we want to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load concentration data and exclude blanks\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Calculated Concentration']\n",
    "data_blank_excluded = data_calibration_excluded[data_calibration_excluded['Sample Comment'] != 'Blank'][selected_columns].copy()\n",
    "data_blank_excluded = data_blank_excluded[~data_blank_excluded['Component Name'].str.contains('IDA|IPS')]\n",
    "# selects only columns available in QCS0 data\n",
    "data_blank_excluded_table = data_blank_excluded.copy().pivot_table(\n",
    "    index='Sample Name', columns='Component Name', values='Calculated Concentration', aggfunc='first'\n",
    "    )\n",
    "data_blank_excluded_table = data_blank_excluded_table.replace(\"<1 points\", np.nan)\n",
    "\n",
    "# Align the columns of PB with data_without_blank\n",
    "common_columns = data_blank_excluded_table.columns.intersection(process_blank_data.columns)\n",
    "PB_aligned = process_blank_data[common_columns]\n",
    "\n",
    "# Convert MDL values to numeric to handle both numeric and string types\n",
    "mdl_values = pd.to_numeric(PB_aligned.loc['MDL'], errors='coerce')\n",
    "\n",
    "# Use np.where with numeric comparison\n",
    "data_blank_excluded_table[common_columns] = np.where(\n",
    "    data_blank_excluded_table[common_columns].apply(pd.to_numeric, errors='coerce') < mdl_values.values,\n",
    "    \"<MDL\", data_blank_excluded_table[common_columns]\n",
    "    )\n",
    "data_blank_excluded_table = data_blank_excluded_table.fillna('<MDL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOEA_TOF_MS is lost\n",
      "['PFPrA_TOF MS', 'N-TAmP-FHxSA_TOF MS', 'N-AP-FHxSA_TOF MS', 'PFEESA_TOF MS', 'PFECHS_TOF MS', 'PF5OHxA_TOF MS', 'PF4OPeA_TOF MS', '3,6-OPFHpA_TOF MS', '11ClPF3OUdS_TOF MS', '9ClPF3ONS_TOF MS', 'DONA_TOF MS', 'HFPO-DA_TOF MS', 'EtFOSA_TOF MS', 'MeFOSA_TOF MS', 'Br-N-EtFOSAA_TOF MS', 'L-N-EtFOSAA_TOF MS', 'Br-N-MeFOSAA_TOF MS', 'L-N-MeFOSAA_TOF MS', '13C3_PFBA_TOF MS', '13C4_PFBA_TOF MS', '13C5_PFPeA_TOF MS', '13C3_PFBS_TOF MS', '13C2 6:2 FTS_TOF MS', '13C2 4:2 FTS_TOF MS', '13C3_HFPO-DA_TOF MS', 'd-EtFOSA_TOF MS', 'd-MeFOSA_TOF MS', 'd5-EtFOSAA_TOF MS', 'd3-MeFOSAA_TOF MS', '13C8_FOSA_TOF MS', '13C8_PFOS_TOF MS', '13C4_PFOS_TOF MS', '13C3_PFHxS_TOF MS', '13C2_PFTeDA_TOF MS', '13C2_PFHxA_TOF MS', '13C2_PFDoA_TOF MS', '13C7_PFUdA_TOF MS', '13C6_PFDA_TOF MS', '13C2_PFDA_TOF MS', '13C9_PFNA_TOF MS', '13C5_PFNA_TOF MS', '13C8_PFOA_TOF MS', '13C2_PFOA_TOF MS', '13C4_PFOA_TOF MS', '13C4_PFHpA_TOF MS', '13C5_PFHxA_TOF MS', '7:3 FTCA_TOF MS', '5:3 FTCA_TOF MS', '3:3 FTCA_TOF MS', 'PFPrS_TOF MS', 'N-EtFBSA-M_TOF MS', 'MeFBSA_TOF MS', '13C2 8:2 FTS_TOF MS'] are lost\n",
      "Component Name  PFBA_TOF MS 10:2 FTS_TOF MS 8:2 FTS_TOF MS 6:2 FTS_TOF MS  \\\n",
      "Sample Name                                                                 \n",
      "240821 PB               NaN             NaN    0.012260663    0.003485621   \n",
      "LB1              0.03548091             NaN            NaN            < 0   \n",
      "LB2             0.017654822             NaN            NaN            < 0   \n",
      "LB3             0.068844399             NaN            NaN    0.031074607   \n",
      "LB4             0.014330745             NaN    0.018883449            < 0   \n",
      "...                     ...             ...            ...            ...   \n",
      "PFOS_72hr_Dup           NaN             NaN            NaN            NaN   \n",
      "PFOS_8hr                NaN             NaN            NaN            NaN   \n",
      "PFOS_8hr_Dup            NaN             NaN            NaN            NaN   \n",
      "PFOS_PC1                NaN             NaN            NaN            NaN   \n",
      "PFOS_PC2                NaN             NaN            NaN            NaN   \n",
      "\n",
      "Component Name 4:2 FTS_TOF MS  FOSA_TOF MS PFTeDA_TOF MS PFTrDA_TOF MS  \\\n",
      "Sample Name                                                              \n",
      "240821 PB         0.058306975  0.368636128           NaN           NaN   \n",
      "LB1               0.066524796   0.18899978           NaN           NaN   \n",
      "LB2               0.049625415   0.26291534           NaN           NaN   \n",
      "LB3               0.064945797  0.092518482           NaN           NaN   \n",
      "LB4               0.045506104  0.641148956           NaN           NaN   \n",
      "...                       ...          ...           ...           ...   \n",
      "PFOS_72hr_Dup     0.056326985  0.002986244   0.056346589           NaN   \n",
      "PFOS_8hr          0.060098217  0.004280594   0.068273421           NaN   \n",
      "PFOS_8hr_Dup       0.06426422  0.002400338   0.044421591           NaN   \n",
      "PFOS_PC1          0.056888888  0.001740043   0.130890036           NaN   \n",
      "PFOS_PC2          0.058858213          NaN   0.105245129           NaN   \n",
      "\n",
      "Component Name PFDoA_TOF MS PFUdA_TOF MS  ... FHxSA_TOF MS FPeSA_TOF MS  \\\n",
      "Sample Name                               ...                             \n",
      "240821 PB               NaN          NaN  ...          NaN          NaN   \n",
      "LB1                     NaN          NaN  ...          NaN          NaN   \n",
      "LB2                     NaN  0.305722133  ...          NaN          NaN   \n",
      "LB3                     NaN   0.06767321  ...  0.120737508          NaN   \n",
      "LB4                     NaN          NaN  ...          NaN          NaN   \n",
      "...                     ...          ...  ...          ...          ...   \n",
      "PFOS_72hr_Dup           NaN          NaN  ...          NaN          NaN   \n",
      "PFOS_8hr                NaN          NaN  ...          NaN          NaN   \n",
      "PFOS_8hr_Dup            NaN          NaN  ...          NaN          NaN   \n",
      "PFOS_PC1                NaN          NaN  ...          NaN          NaN   \n",
      "PFOS_PC2                NaN          NaN  ...          NaN          NaN   \n",
      "\n",
      "Component Name FBSA_TOF MS PFDS_TOF MS Br-PFOS_TOF MS L-PFOS_TOF MS  \\\n",
      "Sample Name                                                           \n",
      "240821 PB              NaN         NaN     0.00589351   0.029585272   \n",
      "LB1                    NaN         NaN            NaN   0.010807701   \n",
      "LB2                    NaN         NaN    0.002952054   0.090994919   \n",
      "LB3             0.00532637         NaN    0.019744949   0.131615722   \n",
      "LB4                    NaN         NaN    0.002265097   0.011567242   \n",
      "...                    ...         ...            ...           ...   \n",
      "PFOS_72hr_Dup          NaN         NaN    0.047711174    0.39052949   \n",
      "PFOS_8hr               NaN         NaN    0.051024316   0.411494587   \n",
      "PFOS_8hr_Dup           NaN         NaN    0.043399007   0.272298951   \n",
      "PFOS_PC1               NaN         NaN    0.013260066   0.075834613   \n",
      "PFOS_PC2               NaN         NaN    0.046831928   0.332032113   \n",
      "\n",
      "Component Name PFHpS_TOF MS Br-PFHxS_TOF MS L-PFHxS_TOF MS PFPeS_TOF MS  \n",
      "Sample Name                                                              \n",
      "240821 PB       0.011622585     0.050301159    0.053321355          NaN  \n",
      "LB1             0.001900522     0.008159982    0.008649926          NaN  \n",
      "LB2             0.090016225     0.060165293    0.063777753  0.001410468  \n",
      "LB3             0.009523909     0.066687183    0.070691232          NaN  \n",
      "LB4                     NaN     0.006871198     0.00728376          NaN  \n",
      "...                     ...             ...            ...          ...  \n",
      "PFOS_72hr_Dup   0.017252785     0.003534527    0.003746749          NaN  \n",
      "PFOS_8hr        0.018833515     0.002322977    0.002462454          NaN  \n",
      "PFOS_8hr_Dup    0.013644348     0.002854827    0.003026238          NaN  \n",
      "PFOS_PC1        0.005317477     0.004312859    0.004571812          NaN  \n",
      "PFOS_PC2        0.012210419     0.004013114    0.004254071          NaN  \n",
      "\n",
      "[99 rows x 29 columns] Component Name         PFBA 10:2 FTS 8:2 FTS      6:2 FTS 4:2 FTS  \\\n",
      "Sample Name                                                         \n",
      "240821 PB       0.047740771      NaN     NaN          NaN     NaN   \n",
      "LB1              0.04201756      NaN     NaN  0.021406844     NaN   \n",
      "LB2             0.042284563      NaN     NaN          NaN     NaN   \n",
      "LB3             0.077386303      NaN     NaN    0.0550734     NaN   \n",
      "LB4             0.044283298      NaN     NaN          NaN     NaN   \n",
      "...                     ...      ...     ...          ...     ...   \n",
      "PFOS_72hr_Dup           NaN      NaN     NaN          NaN     NaN   \n",
      "PFOS_8hr                NaN      NaN     NaN          NaN     NaN   \n",
      "PFOS_8hr_Dup            NaN      NaN     NaN          NaN     NaN   \n",
      "PFOS_PC1                NaN      NaN     NaN          NaN     NaN   \n",
      "PFOS_PC2                NaN      NaN     NaN          NaN     NaN   \n",
      "\n",
      "Component Name         FOSA       PFTeDA PFTrDA PFDoA        PFUdA  ...  \\\n",
      "Sample Name                                                         ...   \n",
      "240821 PB       0.480880171          NaN    NaN   NaN          NaN  ...   \n",
      "LB1             0.227362709          NaN    NaN   NaN  0.055520364  ...   \n",
      "LB2             0.358272828          NaN    NaN   NaN  0.357675895  ...   \n",
      "LB3              0.12121944          NaN    NaN   NaN  0.189469995  ...   \n",
      "LB4             0.759784514          NaN    NaN   NaN          NaN  ...   \n",
      "...                     ...          ...    ...   ...          ...  ...   \n",
      "PFOS_72hr_Dup           NaN  0.159536372    NaN   NaN          NaN  ...   \n",
      "PFOS_8hr                NaN  0.134414472    NaN   NaN          NaN  ...   \n",
      "PFOS_8hr_Dup            NaN  0.099842808    NaN   NaN          NaN  ...   \n",
      "PFOS_PC1                NaN  0.087149764    NaN   NaN          NaN  ...   \n",
      "PFOS_PC2                NaN  0.090822183    NaN   NaN          NaN  ...   \n",
      "\n",
      "Component Name        FHxSA FPeSA FBSA PFDS      Br-PFOS       L-PFOS  \\\n",
      "Sample Name                                                             \n",
      "240821 PB               NaN   NaN  NaN  NaN  0.015032572  0.052721236   \n",
      "LB1                     NaN   NaN  NaN  NaN          NaN          NaN   \n",
      "LB2                     NaN   NaN  NaN  NaN          NaN          NaN   \n",
      "LB3             0.178553139   NaN  NaN  NaN  0.042586851  0.204114706   \n",
      "LB4                     NaN   NaN  NaN  NaN          NaN          NaN   \n",
      "...                     ...   ...  ...  ...          ...          ...   \n",
      "PFOS_72hr_Dup           NaN   NaN  NaN  NaN  0.092095729   0.54610547   \n",
      "PFOS_8hr                NaN   NaN  NaN  NaN  0.088914516  0.509291133   \n",
      "PFOS_8hr_Dup            NaN   NaN  NaN  NaN  0.073707184  0.337493672   \n",
      "PFOS_PC1                NaN   NaN  NaN  NaN  0.023343649  0.102856324   \n",
      "PFOS_PC2                NaN   NaN  NaN  NaN  0.094135413  0.416280986   \n",
      "\n",
      "Component Name        PFHpS     Br-PFHxS      L-PFHxS PFPeS  \n",
      "Sample Name                                                  \n",
      "240821 PB               NaN  0.041360365  0.056193769   NaN  \n",
      "LB1                     NaN          NaN          NaN   NaN  \n",
      "LB2             0.075218637  0.055293422  0.075123751   NaN  \n",
      "LB3                     NaN  0.067437619   0.09162332   NaN  \n",
      "LB4                     NaN          NaN          NaN   NaN  \n",
      "...                     ...          ...          ...   ...  \n",
      "PFOS_72hr_Dup           NaN          NaN          NaN   NaN  \n",
      "PFOS_8hr                NaN          NaN          NaN   NaN  \n",
      "PFOS_8hr_Dup            NaN          NaN          NaN   NaN  \n",
      "PFOS_PC1                NaN          NaN          NaN   NaN  \n",
      "PFOS_PC2                NaN          NaN          NaN   NaN  \n",
      "\n",
      "[99 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# correct channel names in original data (all of the TOF channels are labelled by _TOF MS, only 2 of them are labeled by only _TOF)\n",
    "mask_names = data_blank_excluded['Component Name'].str.endswith('_TOF')\n",
    "data_blank_excluded['Component Name'][mask_names] = [compound + ' MS' for compound in data_blank_excluded['Component Name'][mask_names].to_list()]\n",
    "\n",
    "# get list of all compounds\n",
    "compounds_list = data_blank_excluded['Component Name'].value_counts().index.to_list()\n",
    "\n",
    "# sort compounds by channels\n",
    "compounds_list_channel_tof = [compound for compound in compounds_list if '_TOF MS' in compound]\n",
    "compounds_list_channel_default = [compound for compound in compounds_list if '_TOF MS' not in compound]\n",
    "\n",
    "# try to assign TOF channel_name to each default channel name and keep record of TOF channel values lost in the process\n",
    "compounds_sorted_default = []\n",
    "compounds_sorted_tof = []\n",
    "for compound in compounds_list_channel_default:\n",
    "    if compound + '_TOF MS' in compounds_list_channel_tof:\n",
    "        compounds_sorted_default.append(compound)\n",
    "        compounds_sorted_tof.append(compound + '_TOF MS')\n",
    "    else:\n",
    "        print(f'{compound} is lost')\n",
    "\n",
    "print(f'{[compound for compound in compounds_list_channel_tof if compound not in compounds_sorted_tof]} are lost')\n",
    "mapper = {old_name: new_name for (old_name, new_name) in zip(compounds_sorted_tof, compounds_sorted_default)}\n",
    "\n",
    "# create table with sample name as row, compound as header and calculated concentration as value for default channel\n",
    "concentration_table_all = data_blank_excluded.pivot_table(\n",
    "    values='Calculated Concentration', index=['Sample Name'], columns=['Component Name'], aggfunc='first', dropna=False\n",
    "    )\n",
    "# extract default channel compound columns and tof channel compound values respectively\n",
    "concentration_table_default = concentration_table_all[compounds_sorted_default]\n",
    "concentration_table_default = concentration_table_default.replace({None: np.nan})\n",
    "concentration_table_tof = concentration_table_all[compounds_sorted_tof]\n",
    "concentration_table_tof = concentration_table_tof.replace({None: np.nan})\n",
    "\n",
    "print(concentration_table_tof, concentration_table_default)\n",
    "\n",
    "# cleanup (string to np.nan, and everything else to float)\n",
    "concentration_table_default_np = concentration_table_default.replace(\n",
    "    {'<1 points': np.nan, '< 0': np.nan, 'no root': np.nan, }\n",
    "    ).to_numpy().astype(float)\n",
    "concentration_table_tof_np = concentration_table_tof.replace(\n",
    "    {'<1 points': np.nan, '< 0': np.nan, 'no root': np.nan, }\n",
    "    ).to_numpy().astype(float)\n",
    "\n",
    "# calculate percentage difference and transform back to dataframe\n",
    "ratio = np.divide(\n",
    "    200 * np.subtract(concentration_table_default_np, concentration_table_tof_np),\n",
    "    np.add(concentration_table_default_np, concentration_table_tof_np),\n",
    "    )\n",
    "concentration_table_ratio = pd.DataFrame(\n",
    "    ratio, index=concentration_table_default.index, columns=concentration_table_default.columns,\n",
    "    ).round(decimals=1)\n",
    "\n",
    "# color code percentage deviation\n",
    "def deviation_color_map(val):\n",
    "    if val is np.nan:\n",
    "        return\n",
    "    if -30 <= val <= 30:\n",
    "        return in_range\n",
    "    elif val < -30 or val > 30:\n",
    "        return out_range\n",
    "    \n",
    "\n",
    "# Apply the style function to the entire DataFrame\n",
    "styled_channel_percentage_difference = concentration_table_ratio.style.applymap(deviation_color_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine linear calibration curve based on calibration data.\n",
    "*to be discussed: method for R2 computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhsan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\jhsan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Function to sanitize file names\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Removes special characters from PFAS name to create valid directory names.\"\"\"    \n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", name)\n",
    "\n",
    "# extract PFAS data\n",
    "selected_columns = ['Sample Name', 'Component Name', 'Actual Concentration','IS Actual Concentration','Area','IS Area']\n",
    "data_pfas = data[data['Sample Name'].str.contains('PFAS CS')].copy()\n",
    "data_pfas = data_pfas.fillna(0)\n",
    "data_pfas = data_pfas[~data_pfas['Component Name'].str.contains('IDA|IPS|13C|d3|d5')]\n",
    "data_pfas_ = data_pfas[~data_pfas['Component Name'].str.contains('TOF')]\n",
    "data_pfas_['Concentration/IS Concentration'] = data_pfas_['Actual Concentration']/data_pfas_['IS Actual Concentration']\n",
    "data_pfas_['Area/IS Area'] = data_pfas_['Area']/data_pfas_['IS Area']\n",
    "\n",
    "# Create a list of unique sample names and count them.\n",
    "components = data_pfas_['Component Name'].unique()\n",
    "n_components = len(components)\n",
    "\n",
    "image_paths = []\n",
    "# Iterate over each component and create scatter plots with regression lines\n",
    "for i, component in enumerate(components):\n",
    "    component_data = data_pfas_[data_pfas_['Component Name'] == component]\n",
    "    \n",
    "    # Extract x and y values\n",
    "    x = component_data['Concentration/IS Concentration'].values.reshape(-1, 1)\n",
    "    y = component_data['Area/IS Area'].values\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    # Regression equation\n",
    "    slope = model.coef_[0]\n",
    "    intercept = model.intercept_\n",
    "    equation = f'y = {slope:.2f}x + {intercept:.2f}'\n",
    "\n",
    "    plt.figure(figsize = (8,6))\n",
    "    # Plot with Seaborn\n",
    "    sns.regplot(\n",
    "       # ax=axes[i], \n",
    "        x=x.flatten(), \n",
    "        y=y, \n",
    "        scatter=True, \n",
    "        fit_reg=True,\n",
    "        line_kws={\"color\": \"red\"},  # Color of the regression line\n",
    "        scatter_kws={\"s\": 50, \"alpha\": 0.7},  # Customize scatter points\n",
    "        ci=95\n",
    "    )\n",
    "    # Set the title with the component name\n",
    "    plt.title(f'{component}')\n",
    "    plt.xlabel('Concentration/IS Concentration')\n",
    "    plt.ylabel('Area/IS Area')\n",
    "    plt.text(0.05, 0.95, f'{equation}\\n$R^2$ = {r2:.2f}', \n",
    "             transform=plt.gca().transAxes, \n",
    "             fontsize=10, \n",
    "             verticalalignment='top', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
    "   \n",
    "    # Sanitize the file name\n",
    "    sanitized_component = sanitize_filename(component)\n",
    "    image_path = os.path.join(plot_directory, f'{sanitized_component}.png')\n",
    "    \n",
    "    # Save the plot as an image\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "    \n",
    "    image_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes all relevant data to excel file and adds calibration curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create excel with pandas excelwriter\n",
    "with pd.ExcelWriter(processed_filepath, engine='openpyxl') as writer:\n",
    "    #styled_recovery.to_excel(writer, sheet_name='Recoveries')\n",
    "    styled_ips_norm_recovery.to_excel(writer, sheet_name = 'Calculated Recoveries')\n",
    "    styled_reported_recovery.to_excel(writer, sheet_name = 'Reported Recoveries')\n",
    "    process_blank_data.to_excel(writer, sheet_name='MDL_Values')\n",
    "    data_blank_excluded_table.to_excel(writer, sheet_name='Concentration_filtered_MDL')\n",
    "    #ida_area_piv.to_excel(writer, sheet_name='Area_Pivot')\n",
    "    cal_ida_ips_ratio.to_excel(writer, sheet_name='Calibration IDA_IPS Ratio')\n",
    "    cal_area_ida_piv.to_excel(writer, sheet_name='Calibration IDA')\n",
    "    cal_area_ips_piv.to_excel(writer, sheet_name='Calibration IPS')\n",
    "    sample_ida_ips_ratio.to_excel(writer, sheet_name='Sample IDA_IPS Ratio')\n",
    "    area_ida_piv.to_excel(writer, sheet_name='Sample IDA')\n",
    "    area_ips_piv.to_excel(writer, sheet_name='Sample IPS')\n",
    "    IDL_IQL.to_excel(writer, sheet_name='IDL_IQL')\n",
    "    data_pfas_.to_excel(writer, sheet_name='Calibration Data')\n",
    "    concentration_table_default.to_excel(\n",
    "        writer, sheet_name='Calculated concentration', na_rep='=na()'\n",
    "        )\n",
    "    concentration_table_tof.to_excel(\n",
    "        writer, sheet_name='TOF Calculated concentration', na_rep='=na()'\n",
    "        )\n",
    "    styled_channel_percentage_difference.to_excel(\n",
    "        writer, sheet_name='Concentration Difference (%)', na_rep='=na()'\n",
    "        )\n",
    "\n",
    "workbook = load_workbook(processed_filepath)\n",
    "plot_sheet = workbook.create_sheet('Calibration Curves')\n",
    "    \n",
    "# Insert all images into one sheet in a grid format\n",
    "row_offset = 1  # Start at the first row\n",
    "col_offset = 1  # Start at the first column\n",
    "images_per_row = 2  # Number of images per row\n",
    "\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # Calculate the position for each image\n",
    "    row_position = row_offset + (i // images_per_row) * 15  # Adjust the multiplier to control spacing\n",
    "    col_position = col_offset + (i % images_per_row) * 20   # Adjust the multiplier to control spacing\n",
    "    \n",
    "    # Load the image\n",
    "    img = Image(image_path)\n",
    "    \n",
    "    # Place the image at the calculated position\n",
    "    cell_position = plot_sheet.cell(row=row_position, column=col_position).coordinate\n",
    "    plot_sheet.add_image(img, cell_position)\n",
    "\n",
    "workbook.save(processed_filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

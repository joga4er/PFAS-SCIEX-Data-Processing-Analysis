{"cells":[{"cell_type":"markdown","metadata":{"id":"5ai0Ccju5rTr"},"source":["name: 241016_data_analysis \\\n","date: 10/16/2024 \\\n","version: 1.1 \\\n","github root: #11 \\\n","author: Justin Sankey, Johanna Ganglbauer \\\n","\n","**description**: Takes raw liquit chromatography mass spectroscopy (LCMS) data (exported table from SCIEX Analyst Software), computes recovery rates, method detection limits, and ratios of default channel to MS TOF channel. Generates plots and writes results to excel and creates long format table (.csv) for data publications.\n","\n","**what needs to be implemented**:\n","*   JG: allow seperate recovery filters for separate compounds\n","*   JG: automatically create list of chemicals including precursor mass / child mass and retention time from data\n","*   ...\n","*   **feel free to add your thoughts!**\n","\n","**contact/help/complaints:** johanna.ganglbauer@uri.edu"]},{"cell_type":"markdown","metadata":{"id":"1aYFHWVAC8Q8"},"source":["# Specifying Inputs - Loading files and packages\n","Google colab is a cloud service, so it has no access to the files on your local computer, but you can either upload files manually or connect the google colab to your google drive. To understand the filesystem on the cloud **click on the folder symbol on the left bar**.\\\n","To connect to your google drive run the code cell below. You will find your drive in the **content** folder. If you do not want to aim for this option you can also upload your input files to the **content/sample_data** folder and use it from there.\n","\n","Depending on the server utilization it may take a while to load the preview of your files especially when connected to the google drive.\n","\n","In addition, the block below will load all python packages needed for the following analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37Q4XbjpA1ze"},"outputs":[],"source":["# connect google colab with your google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import all needed packages\n","import os\n","import re\n","import numpy as np\n","import seaborn as sns\n","from openpyxl import load_workbook\n","from openpyxl.drawing.image import Image\n","import math as ma\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","\n","# import pandas and suppress warnings\n","import pandas as pd\n","pd.options.mode.chained_assignment = None"]},{"cell_type":"markdown","metadata":{"id":"7AfPiSd_58H5"},"source":["**Enter in your input filepaths:** \\\n","(1) raw_data_filepaths is a list of files pointing to the exported table from the Sciex Analyst Software you want to analyze. Each file representing results from the core method must end with '_core', each file representing results from the extended method must end with '_extended'. \\\n","(2) idl_2024_filepath is a .csv file containing instrumentation detection limits (IDLs) \\\n","(3) idl_iql_filepath is another .csv file containing instrumentation detection limits for more PFAS components \\\n","(4) processed filepath indicates location and file prefix where your results should be saved to \\\n","(5) plot directory indictes location where your plots should be saved to. \\\n","\n","for (2) and (3) default files available on the Lohmann drive under example_input.\n","\n","Once you connected google colab to the drive or uploaded your files to the server file system the best way to get your input filepaths is to search the files you want to use in the filesystem of google colab (click folder symbol on the left bar), right click on the file and choose \"copy filepath\". Then you can directly insert the related filepath to your Code.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZozFL6t7sax"},"outputs":[],"source":["# raw data upload file path\n","raw_filepaths = [\n","    r'/content/drive/Shareddrives/LOHMANN LAB/STEEP project 4/4_LC MS analysis/Data_Analysis/example_input/test_data_core.txt',\n","    r'/content/drive/Shareddrives/LOHMANN LAB/STEEP project 4/4_LC MS analysis/Data_Analysis/example_input/test_data_extended.txt',\n","]\n","\n","# file paths for IDL and IQL data - not meant to be adopted\n","idl_2024_filepath = r'/content/drive/Shareddrives/LOHMANN LAB/STEEP project 4/4_LC MS analysis/Data_Analysis/example_input/IDL_2024.csv'\n","idl_iql_filepath = r'/content/drive/Shareddrives/LOHMANN LAB/STEEP project 4/4_LC MS analysis/Data_Analysis/example_input/IDL_2024.csv'\n","\n","# processed data output excel file path\n","processed_filepath =r'/content/outputs/test_data'\n","\n","# directory to save plots to\n","plot_directory = r'/content/plots'"]},{"cell_type":"markdown","metadata":{"id":"ewIeK7Ak7v1_"},"source":["**Enter in your parameters:**\n","\n","(1) Change what you deem to be an acceptable recovery range. \\\n","(2) Indicate the maximal allowed percentage deviation between MS TOF channel and MS/MS channel. \\\n","(3) Provide a default value for the instrumentation detection limit (IDL) in case the component is not listed in the csv. \\\n","(4) Indicate which samples you want to use to calculate MDL values. You can only use terms which are used in the \"Sample Comment\" column of your input data. \\\n","(5) Introduce the hard facts about your sample. \\\n","\n","A common source of confusion is the fact that the actual concentration of targeted compounds in the LCMS analysis is calculated in ng/sample by the developed method.\\\n","To convert the results to ng/l (water samples) or ng/g (tissue, sediment, etc.) you need to indicate the 'non extracted sample quantity'. \\\n","To compare the results to the calibration data you need to indicate the volume of your extracted sample. (it is commonly 0.5 ml)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT4UCiwFF_b0"},"outputs":[],"source":["# color-coding and range for recoveries table\n","in_range = 'background-color: green'\n","in_range_min_val = 0.8\n","in_range_max_val = 1.2\n","out_range = 'background-color: red'\n","out_range_min_val = 0.4\n","out_range_max_val = 1.6\n","question_range = 'background-color: yellow'\n","\n","# threshold for acceptance of absolute percentage difference between default channel and TOF MS channel\n","allowed_channel_deviation = 100\n","\n","# idl value, if nothing is provided\n","idl_unknown = 1e-3\n","\n","# samples used for MDL calculatation - keywords need to be used in \"Sample Comment\" column of input data\n","# if you want to use IDLs only, use an empty list.\n","mdl_selection = [\n","    'IS Check', 'Process Blank', 'Water Extraction Blank',\n","]\n","\n","# hard facts about your sample - to correct compare IPS concentrations and convert the PFAS concentration.\n","ips_concentration_calibration = 4  # ng/ml\n","extracted_sample_volume = 0.5  # ml\n","sample_unit = 'l'  # eiter 'l' for liter or 'g' for gram\n","nonextracted_sample_quantity = 1 # indicate the weight (if sample_unit is 'g') or volume (if sample unit is 'l') or your non-extracted sample."]},{"cell_type":"markdown","metadata":{"id":"eBdL-aTpGFpY"},"source":["The following  code block reads in data and cleans it up."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4H77BcO6GO4M"},"outputs":[],"source":["# Parse inputs\n","if sample_unit not in ['l', 'g']:\n","    raise Exception(\"\"\"Please use either 'g' or 'l' for variable sample_unit. \"\"\")\n","\n","# Ensure file path and folder path exist to write outputs to and create folders, if they do not exist\n","folder_path = os.path.dirname(processed_filepath)\n","if folder_path and not os.path.exists(folder_path):\n","    os.makedirs(folder_path)\n","processed_filepath_xlsx = processed_filepath + '.xlsx'\n","processed_filepath_csv = processed_filepath + '.csv'\n","\n","if not os.path.exists(plot_directory):\n","    os.makedirs(plot_directory)\n","\n","# Define columns of input which are needed for further processes:\n","columns_considered = [\n","    'Sample Name', 'Sample Index', 'Sample Comment', 'Sample Type',\n","    'Component Name',  'Component Group Name', 'Component Comment', 'IS Name',\n","    'Acquisition Date & Time', 'Injection Volume', 'Used',\n","    'Calculated Concentration', 'Actual Concentration', 'IS Actual Concentration',\n","    'Reported Recovery', 'IDA Average Response Factor',\n","    'Area', 'IS Area', 'Area IDA', 'Area IPS',\n","    'Retention Time', 'IS Retention Time', 'Retention Time Error (%)', 'Retention Time Delta (min)',\n","    'Start Time', 'IS Start Time', 'End Time', 'IS End Time',\n","    'Precursor Mass', 'Fragment Mass',\n","]\n","\n","# Load input data files and put them all in one dataframe\n","data = pd.DataFrame()  # initialize empty data frames\n","component_index = 0  # initialize Component Index\n","for file in raw_filepaths:\n","    # read in file\n","    if file[-4:] == '.csv':\n","        this_data = pd.read_csv(file, delimiter=',', encoding='utf-8', low_memory=False, header=0,)\n","    elif file[-4:] == '.txt':\n","        this_data = pd.read_csv(file, delimiter='\\t', encoding='utf-8', low_memory=False, header=0,)\n","    else:\n","        print('Raw input file paths must either be .csv or .txt files.')\n","\n","    # increase component index to remain unique for multiple data frames\n","    this_data['Component Index'] = this_data['Component Index'] + component_index\n","    component_index += max(this_data['Component Index'])\n","\n","    # make sure each sample name ends with Ext for extended method and with Core for core method\n","    if file[-12:-4] == 'extended':\n","        mask_names = this_data['Sample Name'].str.endswith('Ext')\n","        this_data['Sample Name'][~mask_names] = [compound + ' Ext' for compound in this_data['Sample Name'][~mask_names].to_list()]\n","    elif file[-8:-4] == 'core':\n","        mask_names = this_data['Sample Name'].str.endswith('Core')\n","        this_data['Sample Name'][~mask_names] = [compound + ' Core' for compound in this_data['Sample Name'][~mask_names].to_list()]\n","    else:\n","        print('If you combine core method and extended method make sure your input file names end with _core and _extended respectively.')\n","\n","    # append actual dataframe in list (this_data) to huge dataframe (data)\n","    if data.empty:\n","        data = this_data[columns_considered]  # initialize data in first step (when data is empty)\n","    else:\n","        data = pd.concat([data, this_data[columns_considered]], ignore_index=True)  # append to data\n","\n","# Clean up 'Calculated Concentration' column - set all strange strings to NaN\n","data['Calculated Concentration'] = data['Calculated Concentration'].replace(\n","    {'<1 points': np.nan, '< 0': np.nan, 'no root': np.nan, 'NaN': np.nan}\n","    ).astype('float')\n","\n","# Replace 'IPS-13C2_PFOA' values: optional, only when component name occurs\n","if any(data['Component Name'].isin(['IPS-13C2_PFOA'])):\n","    data['Component Group Name'] = data['Component Group Name'].replace('IPS-13C2_PFOA', 'IPS-13C4_PFOA')\n","\n","    # Find rows where 'Component Group Name' is 'IPS-13C4_PFOA' (after replacement)\n","    mask = data['Component Group Name'] == 'IPS-13C4_PFOA'\n","\n","    # Iterate through each of these rows and replace area in column\n","    for idx, row in data[mask].iterrows():\n","        sample_name = row['Sample Name']\n","\n","        # Find the corresponding row with 'Component Name' == 'IPS-13C4_PFOA' and the same 'Sample Name'\n","        matching_row = data[(data['Component Name'] == 'IPS-13C4_PFOA') & (data['Sample Name'] == sample_name)]\n","\n","        if not matching_row.empty:\n","            # Update the 'Area IPS' with the value from 'Area' in the matching row\n","            data.at[idx, 'Area IPS'] = matching_row['Area'].values[0]\n","\n","# Correct channel names in original data (all of the TOF channels are labelled by _TOF MS, only 2 of them are labeled by only _TOF)\n","mask_names = data['Component Name'].str.endswith('_TOF')\n","data['Component Name'][mask_names] = [compound + ' MS' for compound in data['Component Name'][mask_names].to_list()]\n","\n","# some have an underscore between TOF and MS, this is removed\n","mask_names = data['Component Name'].str.endswith('_TOF_MS')\n","data['Component Name'][mask_names] = [compound[:-3] + ' MS' for compound in data['Component Name'][mask_names].to_list()]\n","\n","# make sample index equal if one sample exist as both \"Core Method\" and \"Extended Method\"\n","sample_names = data['Sample Name'].unique()\n","# combine indices of Core Method and Extended Method if both are available\n","detect = 0\n","index_mapper = {}\n","for sample_name in sample_names:\n","    if sample_name[-3:] == 'Ext' and sample_name[:-3] + 'Core' in sample_names:\n","        sample_indices = data.loc[data['Sample Name'].isin([sample_name, sample_name[:-3] + 'Core']), 'Sample Index'].unique()\n","        data.loc[data['Sample Index'].isin(sample_indices), 'Sample Index'] = sample_indices[0]\n","        index_mapper[sample_indices[0]] = sample_name[:-3]\n","        detect+=1\n","    elif sample_name[-4:] == 'Core':\n","        continue\n","    else:\n","        print(f'The sample {sample_name} has no related Core Method. Find out if this is a problem.')\n","\n","# Get the order of components and split it to default channel (MS/MS) and TOF channel.\n","# If either channel is not available a copy of the other one is used respectively.\n","if detect > 0:\n","    first_sample_id = sample_indices[0]\n","else:\n","    first_sample_id = data['Sample Index'].value_counts().index[0]  # index of first sample\n","components_sorted_duplicate = data.loc[data['Sample Index'] == first_sample_id, 'Component Name']  # channel names of first sample\n","components_sorted_duplicate = components_sorted_duplicate[~components_sorted_duplicate.str.contains('IDA|IPS|13C')].to_list()  # channel names excluding IPS and IDA\n","\n","# remove duplicates from components_sorted_duplicate\n","components_sorted = []\n","[components_sorted.append(x) for x in components_sorted_duplicate if x not in components_sorted]\n","\n","# initialize and fill lists of sorted components\n","components_default = []\n","components_tof = []\n","skip_index = []\n","for (index, component) in enumerate(components_sorted):\n","    if index in skip_index:\n","        continue\n","    if '_TOF MS' in component:\n","        if component[:-7] in components_sorted:\n","            components_default.append(component[:-7])\n","            components_tof.append(component)\n","            skip_index.append(components_sorted.index(component[:-7]))\n","        else:\n","            continue\n","    else:\n","        components_default.append(component)\n","        if component + '_TOF MS' in components_sorted:\n","            components_tof.append(component + '_TOF MS')\n","            skip_index.append(components_sorted.index(component + '_TOF MS'))\n","        else:\n","            components_tof.append(component)\n","\n","# display settings\n","pd.set_option('display.max_rows', None)  # Show all rows\n","pd.set_option('display.max_columns', None)  # Show all columns\n","pd.set_option('display.max_colwidth', None)  # Show full width of columns"]},{"cell_type":"markdown","metadata":{"id":"MgNZioHzGV1b"},"source":["The following code block separates data in calibration data, data for mdl calculation (blank data) and quantification data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cez1yIkYGhWg"},"outputs":[],"source":["# Split data into quantification data, calibration data, and blanks for mdl calculation\n","calibration_only = data[(data['Sample Type'] == 'Standard')]\n","quantification_blank = data[(data['Sample Type'] != 'Standard')]\n","\n","if not quantification_blank.empty:\n","    # select data for computation of mdl and exclude it from quantification data\n","    if mdl_selection == []:\n","        blank_only = None\n","        quantification_only = quantification_blank\n","    else:\n","        blank_selection = quantification_blank['Sample Comment'].str.contains('|'.join(mdl_selection))\n","        if sum(blank_selection) == 0:\n","            (f'Be careful, no samples have been collected for the MDL calculation because {mdl_selection} is not a Sample Comment.')\n","            print(f'If you do not select blank set variable mdl_selection to [].')\n","        if sum(blank_selection) == len(quantification_blank):\n","            print(f'Be careful, all samples have been collected for the MDL calculation.')\n","            print(f'If this is not what you want reset the variable mdl_selection in the top block.')\n","        blank_selection.replace({np.nan: False}, inplace=True)\n","        blank_only = quantification_blank[blank_selection]\n","        quantification_only = quantification_blank[~blank_selection]"]},{"cell_type":"markdown","metadata":{"id":"1wSLW9sjGkPS"},"source":["# Recovery Rates\n","To avoid misunderstandings, in the following two abbreviations are extensively used:\n","- IDA: isotope dilution analysis, also known as SS=surrogate standard or EIS=extracted internal standard\n","- IPS: isotope performance standard, also known as IS=injection standard or NIS=non-extracted internal standard\n","\n","**The following two blocks calculate response factors from calibration data:**\\\n","ratio of (i) calculated area of IDA * **actual concentration of IPS** and (ii) calculated area of IPS * actual concentration of IDA. \\\n","The data is saved to an excel file and a boxplot of response factors is created.\n","\n","Note: The response factor calculation within sciex uses the ratio of (i) calculated area of IDA and (ii) calculated area of IPS * actual concentration of IDA. \\\n","As the concentration of IPS is missing in the calculation, the response factors deviate by a factor of 4, which is the actual concentration of IPS in the calibration data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"II-BctklGp7V"},"outputs":[],"source":["# define funtion which calculates the IDA IPS ratio.\n","# challenge - search right IPS row indicated in the Component Group Name of IDA.\n","def calculate_ida_ips_ratio(data: pd.DataFrame, column_name:str, ) -> pd.DataFrame:\n","    \"\"\"Calculates IDA area times IPS concentration divided by IPS area times IDA concentration and save the results in the indicated column.\n","\n","    :param data: Entire data junk (including all rows and the following columns:\n","    Component Name, Sample Index, Component Group Name, Actual Concentration, Area, and IDA Average Response Factor\n","    :type data: pd.DataFrame\n","    :param column_name: name of column, the calculated ratio should be saved to\n","    :type column_name: str\n","    :return: Data junk only containing IDA rows with the corresponding ratio saved to new column\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    data_only_ida = data[data['Component Name'].str.contains('IDA')]\n","    data_only_ida.loc[:,f'{column_name}'] = [np.nan] * len(data_only_ida)\n","    data_only_ida.loc[:,'IPS Area'] = [np.nan] * len(data_only_ida)\n","    data_only_ida.loc[:,'IPS Concentration'] = [np.nan] * len(data_only_ida)\n","\n","    # calculate recovery rate for every component, end every sample\n","    for row_index in data_only_ida.index:\n","        sample_index = data_only_ida.loc[row_index, 'Sample Index']\n","        ips_channel_name = data_only_ida.loc[row_index, 'Component Group Name']\n","\n","        sample_name = data_only_ida.loc[row_index, 'Sample Name']\n","        corresponding_ips_area_row = data[(\n","            (data['Sample Index'] == sample_index) &\n","            (data['Component Name'] == ips_channel_name) &\n","            (data['Sample Name'] == sample_name)\n","            )]\n","        data_only_ida.loc[row_index, 'IPS Area'] = corresponding_ips_area_row['Area'].iloc[0]\n","        data_only_ida.loc[row_index, 'IPS Concentration'] = corresponding_ips_area_row['Actual Concentration'].iloc[0]\n","        data_only_ida.loc[row_index, f'{column_name}'] = \\\n","            (data_only_ida.loc[row_index, 'Area'] * corresponding_ips_area_row['Actual Concentration'].iloc[0]) \\\n","            / (corresponding_ips_area_row['Area'].iloc[0] * data_only_ida.loc[row_index, 'Actual Concentration'])\n","    return data_only_ida"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuWK_jF4GydT"},"outputs":[],"source":["# Extract values of IDAs and IPS\n","# Save basic sample information as well as areas of intensity peak, actual concentration and Component Group Name.\n","# The 'Component Group Name' is useful to assoiciate the right IPS to each IDA.\n","\n","# calucluate IDA IPS ratio to compute response factors with calibration data\n","calibration_only_ida = calculate_ida_ips_ratio(\n","    data=calibration_only, column_name='Response Factor from Scratch',\n","    )\n","\n","# create data frame with this response factor calculation (from scratch), the standard deviation and the original values evaluated by Sciex,\n","response_factor = calibration_only_ida.groupby('Component Name', as_index=False)['Response Factor from Scratch'].mean()\n","response_factor['Response Factor Std'] = calibration_only_ida.groupby('Component Name')['Response Factor from Scratch'].std().to_list()\n","response_factor['Response Factor Sciex'] = calibration_only_ida.groupby('Component Name')['IDA Average Response Factor'].mean().to_list()\n","response_factor.rename(columns={'Response Factor from Scratch': 'Response Factor Mean'}, inplace=True)\n","response_factor.index = response_factor['Component Name']\n","response_factor.drop(columns=['Component Name'], inplace=True)\n","\n","# write response factor to excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl') as writer:\n","    response_factor.to_excel(writer, sheet_name='Response Factor')\n","\n","# create and save response factor box plots\n","image_path = os.path.join(plot_directory, 'response_factors.png')\n","fig, ax = plt.subplots(figsize=(8, 8))\n","calibration_only_ida.boxplot(column='Response Factor from Scratch', by='Component Name', ax=ax,)\n","ax.plot([np.nan] + (response_factor['Response Factor Sciex'] * 4).to_list(), color='red', linestyle='', marker=\"o\",)\n","ax.plot([np.nan] + (response_factor['Response Factor Sciex']).to_list(), color='blue', linestyle='', marker=\"o\",)\n","fig.suptitle('')\n","ax.set_title('')\n","plt.ylabel('Response Factor (IDA area/IPS area)')\n","plt.xticks(rotation=90)\n","box_patch = mpatches.Patch(color='blue', fill=False, label='data')\n","blue_patch = mpatches.Patch(color='blue', label='RF Sciex')\n","red_patch = mpatches.Patch(color='red', label='4 * RF Sciex')\n","plt.legend(handles=[box_patch, red_patch, blue_patch])\n","plt.savefig(image_path, bbox_inches='tight')\n","plt.show()\n","\n","# save response factor box plot to excel file\n","workbook = load_workbook(processed_filepath_xlsx)\n","plot_sheet = workbook.create_sheet('Details RF')\n","\n","img = Image(os.path.join(plot_directory, 'response_factors.png'))\n","\n","cell_position = plot_sheet.cell(row=1, column=1).coordinate\n","plot_sheet.add_image(img, cell_position)\n","\n","workbook.save(processed_filepath_xlsx)"]},{"cell_type":"markdown","metadata":{"id":"c7nXgB8fG3ep"},"source":["The following block is useful to detect and correct wrong information about the amount of IPS added to the samples. \\\n","The ratio of mean IPS area in the samples and mean IPS area in the calibration data is a good indicator.\n","\n","If the IPS areas are in the same range for calibration and quantification, also the added IPS concentration should be in the same range. \\\n","If the IPS areas of your quantification is twice as much as in the calibration, also the added IPS concentration should be twice as musch.\n","\n","**Source of confusion:**\n","The IPS concentration in the calibration data is given per milli liter.\\\n","The IPS concentration in your quantification data is given per sample. When you have a volume of 0.5 ml for your extracted sample the IPS concentration in the quantification will be twice as high.\n","\n","Here, the IPS concentration in your sample is converted from concentration per sample to concentration per ml to have a fair comparison to the calibration data. \\\n","The data indicated in 'Actual Concentration' Column is usually given per sample - it is converted by dividing through the volume of your extracted samples.\n","\n","After checking the graph, make sure you inputed the amount of standard you added in the SCIEX software correctly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLfcCxunG9sH"},"outputs":[],"source":["# Calculate IPS average area per compound in calibration data and plot it\n","calibration_only_ips = calibration_only[calibration_only['Component Name'].str.contains('IPS')]\n","quantification_blank_only_ips = quantification_blank[quantification_blank['Component Name'].str.contains('IPS')]\n","\n","# evaluate mean per component\n","calibration_ips_area_averages = calibration_only_ips.groupby('Component Name')['Area'].mean()\n","quantification_blank_ips_area_averages = quantification_blank_only_ips.groupby('Component Name')['Area'].mean()\n","\n","# evaluate IPS concentration in quantification\n","ips_concentration = quantification_blank_only_ips['Actual Concentration'].mean() / extracted_sample_volume\n","\n","# create plot for comparison\n","image_path = os.path.join(plot_directory, 'ips_areas.png')\n","fig, ax = plt.subplots(ncols=2, figsize=(8, 8), sharey=True)\n","calibration_only_ips.boxplot(column='Area', by='Component Name', ax=ax[0])\n","ax[0].plot([np.nan] + calibration_ips_area_averages.to_list(), color='red', linestyle='', marker=\"o\", label='calibration average')\n","quantification_blank_only_ips.boxplot(column='Area', by='Component Name', ax=ax[1])\n","ax[1].plot([np.nan] + quantification_blank_ips_area_averages.to_list(), color='red', linestyle='', marker=\"o\", label='quantification average')\n","fig.suptitle('')\n","ax[0].set_title('Calibration: 4 ng/ml')\n","ax[1].set_title(f'Quantification: {ips_concentration} ng/ml (?)')\n","ax[0].set_xticks(\n","    ticks=range(len(calibration_ips_area_averages) + 1),\n","    labels=[''] + calibration_ips_area_averages.index.to_list(), rotation=90\n","    )\n","ax[1].set_xticks(\n","    ticks=range(len(quantification_blank_ips_area_averages) + 1),\n","    labels=[''] + quantification_blank_ips_area_averages.index.to_list(), rotation=90\n","    )\n","ax[0].set_ylabel('IPS area')\n","[this_ax.set_xlabel('') for this_ax in ax]\n","plt.savefig(image_path, bbox_inches='tight')\n","plt.show()\n","\n","# save IPS area comparison plot to excel file\n","workbook = load_workbook(processed_filepath_xlsx)\n","plot_sheet = workbook.create_sheet('Details IPS concentration')\n","\n","img = Image(os.path.join(plot_directory, 'ips_areas.png'))\n","\n","cell_position = plot_sheet.cell(row=1, column=1).coordinate\n","plot_sheet.add_image(img, cell_position)\n","\n","workbook.save(processed_filepath_xlsx)"]},{"cell_type":"markdown","metadata":{"id":"BYEDfn9hHBJP"},"source":["The following block calculates recovery rates for each IDA compound in each sample.\n","$$\n","recovery~rate = \\frac{\\frac{area_{IDA~sample}~\\cdot~concentration_{IPS~sample}}{area_{IPS~sample}~\\cdot~concentration_{IDA~sample}}}{average(\\frac{area_{IDA~calibration}~\\cdot~concentration_{IPS~calibration}}{area_{IPS~calibration}~\\cdot~concentration_{IDA~calibration}})} = \\frac{ratio}{response~factor}\n","$$\n","\n","The recovery rates are illustrated for all samples and all IDAs to enable a quick visual sanity check.\n","\n","Recovery rate computed within the SCIEX software is not normalized by concentration. So the recovery rate calculated by SCIEX reads:\n","$$\n","recovery~rate = \\frac{\\frac{area_{IDA~sample}}{area_{IPS~sample}}}{average(\\frac{area_{IDA~calibration}}{area_{IPS~calibration}})}\n","$$\n","\n","The uncertainty of the recovery rate is indicate by a maximum error method - for now, you can just ignore this part...\n","$$\n","\\Delta recovery~rate = \\Delta response~factor \\cdot \\frac{ratio}{response~factor^{2}} + \\Delta ratio \\cdot \\frac{1}{response~factor}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aznnAlxKHJ6p"},"outputs":[],"source":["# define color maps for excel output\n","def color_map(val):\n","    if val is np.nan:\n","        return\n","    if in_range_min_val <= val <= in_range_max_val:\n","        return in_range\n","    elif val < out_range_min_val or val > out_range_max_val:\n","        return out_range\n","    else:\n","        return question_range\n","\n","# Select ida rows from quantification data and calculate ida ips ratio\n","# function is defined in previous block\n","quantification_ida = calculate_ida_ips_ratio(\n","    data=quantification_only, column_name=\"IDA-IPS Ratio\",\n","    )\n","\n","# Assign right response factor to each IDA\n","quantification_ida.loc[:, 'Response Factor Mean'] = [np.nan] * len(quantification_ida)\n","quantification_ida.loc[:, 'Response Factor Std'] = [np.nan] * len(quantification_ida)\n","\n","for component in response_factor.index:\n","    quantification_ida.loc[quantification_ida['Component Name'] == component, 'Response Factor Mean'] = response_factor.loc[component, 'Response Factor Mean']\n","    quantification_ida.loc[quantification_ida['Component Name'] == component, 'Response Factor Std'] = response_factor.loc[component, 'Response Factor Std']\n","\n","# Calculate recovery rate and its related uncertainty\n","quantification_ida.loc[:, 'Recovery Rate'] = quantification_ida.loc[:, 'IDA-IPS Ratio'] / quantification_ida.loc[:, 'Response Factor Mean']\n","quantification_ida.loc[:, 'Recovery Rate Uncertainty 1'] = quantification_ida.loc[:,'Response Factor Std'] * quantification_ida.loc[:,'IDA-IPS Ratio'] \\\n","     / (quantification_ida.loc[:, 'Response Factor Mean'] * quantification_ida.loc[:, 'Response Factor Mean'])\n","\n","# Put computed recovery rate, and recovery rate from the sciex software in pivot table\n","recovery = quantification_ida.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values='Recovery Rate', aggfunc='mean', dropna=False,\n","    )\n","recovery.rename(index=index_mapper, inplace=True)\n","\n","recovery_sciex = quantification_ida.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values='Reported Recovery', aggfunc='mean', dropna=False,\n","    ) / 100\n","recovery_sciex.rename(index=index_mapper, inplace=True)\n","\n","# Write recovery rate to excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl', mode='a') as writer:\n","    recovery.style.map(color_map).to_excel(writer, sheet_name='Recovery Rate')\n","    recovery_sciex.style.map(color_map).to_excel(writer, sheet_name='Sciex Recovery Rate')\n","\n","# Multiply recovery rate by 100\n","quantification_ida[\"Recovery Rate\"] = 100 * quantification_ida[\"Recovery Rate\"]\n","\n","# Box plot for recovery rates\n","image_path = os.path.join(plot_directory, 'recovery_rates_box.png')\n","fig, ax = plt.subplots(figsize=(8, 8))\n","quantification_ida.boxplot(column='Recovery Rate', by='Component Name', ax=ax,)\n","ax.set_ylim([0,500])\n","fig.suptitle('')\n","ax.set_title('')\n","plt.ylabel('Recovery Rate')\n","plt.xticks(rotation=90)\n","plt.legend()\n","plt.savefig(image_path, bbox_inches='tight')\n","plt.show()\n","\n","# plot data as points for recovery rates:\n","plot_data = quantification_ida.groupby('Sample Name')  # group data for plotting\n","cmap = plt.cm.get_cmap('tab20', len(plot_data)) # initialize colours\n","image_path = os.path.join(plot_directory, 'recovery_rates.png')  # set path for figure\n","\n","fig, ax = plt.subplots(figsize=(8, 8))\n","for index, (title, group) in enumerate(plot_data):\n","    group.set_index(group['Component Name'], inplace=True)\n","    group.sort_index(inplace=True)\n","    group.drop_duplicates(keep='first', inplace=True)\n","    group.plot(\n","        y='Recovery Rate', ax=ax, marker='.', linestyle='None', label=title, grid=True, color = cmap(index),\n","    )\n","ax.set_ylim([0,500])\n","fig.suptitle('')\n","ax.set_xticks(range(len(group)))\n","ax.set_xticklabels(group['Component Name'], rotation=90)\n","ax.set_title('')\n","plt.xticks(rotation=90)\n","plt.ylabel('Recovery Rate')\n","plt.legend(loc='center right', bbox_to_anchor=(1.4, 0.5))\n","plt.savefig(image_path, bbox_inches='tight')\n","plt.show()\n","\n","# save recovery rate plot to excel file\n","workbook = load_workbook(processed_filepath_xlsx)\n","plot_sheet = workbook.create_sheet('Details Recovery Rates')\n","\n","img1 = Image(os.path.join(plot_directory, 'recovery_rates_box.png'))\n","img1.anchor = 'A1'\n","plot_sheet.column_dimensions['A'].width = img1.width / 6\n","plot_sheet.row_dimensions[1].height = img.height\n","plot_sheet.add_image(img1)\n","\n","img2 = Image(os.path.join(plot_directory, 'recovery_rates.png'))\n","img2.anchor = 'B1'\n","plot_sheet.column_dimensions['B'].width = img2.width / 6\n","plot_sheet.add_image(img2)\n","\n","workbook.save(processed_filepath_xlsx)"]},{"cell_type":"markdown","metadata":{"id":"Qz6xpekBIQaN"},"source":["In the following code block the right recovery rate is assigned to each PFAS. Each PFAS component has a corresponding IDA - the recovery rate is deduced from the recovery rate of the corresponding IDA.\n","The assignment works for each sample by using the 'IS Name' column which provides information on which IDA standard is associated to which PFAS.\\\n","\n","When both core method and extended method are combine, some of the PFAS components may be measured twice - in that case the average of the recovery rates and the average of the concentrations is used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTpJsEEvIYij"},"outputs":[],"source":["# Initialize data frame for following assignments, select only needed columns and use reasonable naming.\n","selected_columns = [\n","    'Sample Name', 'Sample Index', 'Acquisition Date & Time', 'Component Name', 'IS Name', 'Calculated Concentration', 'Area',\n","    ]\n","quantification_pfas_default = quantification_only[selected_columns]\n","quantification_pfas_default.rename(columns={'IS Name': 'IDA Name'}, inplace=True)\n","\n","# Get only PFAS default channels\n","quantification_pfas_default = quantification_pfas_default[quantification_pfas_default['Component Name'].isin(components_default)]\n","\n","# Assign right recovery rate and uncertainty to each PFAS compound\n","quantification_pfas_default.loc[:,'IDA Area'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'IDA Concentration'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'IPS Area'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'IPS Concentration'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'IPS Name'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'Recovery Rate'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'Recovery Rate Uncertainty 1'] = [np.nan] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:,'Recovery Rate Sciex'] = [np.nan] * len(quantification_pfas_default)\n","for row_index in quantification_pfas_default.index:\n","    sample_index = quantification_pfas_default.loc[row_index, 'Sample Index']\n","    ida_channel_name = quantification_pfas_default.loc[row_index, 'IDA Name']\n","    if ida_channel_name in quantification_ida['Component Name'].to_list():\n","        recovery_row = quantification_ida[(\n","            (quantification_ida['Component Name'] == ida_channel_name) &\n","            (quantification_ida['Sample Index'] == sample_index)\n","        )]\n","        quantification_pfas_default.loc[row_index,'IDA Area'] = recovery_row.loc[:,'Area'].mean()\n","        quantification_pfas_default.loc[row_index,'IDA Concentration'] = recovery_row.loc[:,'Actual Concentration'].mean()\n","        quantification_pfas_default.loc[row_index,'IPS Area'] = recovery_row.loc[:,'IPS Area'].mean()\n","        quantification_pfas_default.loc[row_index,'IPS Concentration'] = recovery_row.loc[:,'IPS Concentration'].mean()\n","        quantification_pfas_default.loc[row_index, 'IPS Name'] = \\\n","            recovery_row.loc[:,'Component Group Name'].to_list()[0]\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate'] = \\\n","            recovery_row.loc[:,'Recovery Rate'].mean()\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate Uncertainty 1'] = \\\n","            (recovery_row.loc[:,'Recovery Rate Uncertainty 1'].round(decimals=3) * 100).mean()\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate Sciex'] = \\\n","            recovery_row.loc[:,'Reported Recovery'].mean()\n","\n","    else:\n","        quantification_pfas_default.loc[row_index,'IDA Area'] = np.nan\n","        quantification_pfas_default.loc[row_index,'IDA Concentration'] = np.nan\n","        quantification_pfas_default.loc[row_index,'IPS Area'] = np.nan\n","        quantification_pfas_default.loc[row_index,'IPS Concentration'] = np.nan\n","        quantification_pfas_default.loc[row_index, 'IPS Name'] = np.nan\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate'] = np.nan\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate Uncertainty 1'] = np.nan\n","        quantification_pfas_default.loc[row_index, 'Recovery Rate Sciex'] = np.nan\n","\n","for column in ['Recovery Rate', 'Recovery Rate Uncertainty 1', 'Recovery Rate Sciex']:\n","    quantification_pfas_default[f'{column}'] = quantification_pfas_default[f'{column}'].round(decimals=1)\n","\n","# Put computed recovery rate in pivot table\n","recovery = quantification_pfas_default.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values='Recovery Rate', aggfunc='first', dropna=False,\n","    )\n","recovery.rename(index=index_mapper, inplace=True)\n","recovery = recovery[components_default]\n","\n","# Write to excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl', mode='a') as writer:\n","    recovery.to_excel(writer, sheet_name='Recovery Rate Extended')\n","\n","# Apply filter to measurements: samples and PFAS components with recovery rates being below the lower threshold or above the upper thresholds will be flagged.\n","quantification_pfas_default.loc[:,'Poor Recovery'] = ~quantification_pfas_default['Recovery Rate'].between(\n","    out_range_min_val * 100, out_range_max_val * 100, inclusive='both',\n","    )\n","quantification_pfas_default.loc[quantification_pfas_default['Recovery Rate'].isnull(), 'Poor Recovery'] = False"]},{"cell_type":"markdown","metadata":{"id":"ydKLNnO4KhFy"},"source":["# Method Detection Limits\n","The following block compute method detection limits (MDL) based on average and standard deviation of selected samples (process blanks, etc.). \\\n","The code use instrument detection limits (IDL) for the PFAS compounds not included in the process blanks. \\\n","For some comounds the IDL may not be included in the input files, then the default value is used.\\\n","\n","Moreover, a new column 'Below Detection Threshold' is introduces, which indicates all Calculated Concentration Values of PFAS quantification below the determined detection limits."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSgXlrjDRDkn"},"outputs":[],"source":["# Make empty dataframe if blanks for MDL calculations are not available\n","mdl = pd.DataFrame(index=components_default)\n","mdl['Mean Concentration'] = [np.nan] * len(mdl)\n","mdl['Std Concentration'] = [np.nan] * len(mdl)\n","mdl['MDL'] = [np.nan] * len(mdl)\n","mdl['IDL'] = [np.nan] * len(mdl)\n","\n","if not blank_only.empty:\n","    blank_only_default = blank_only[blank_only['Component Name'].isin(components_default)]\n","    # create data frame with average and standard deviation values for MDL calculation and caluclate MDL\n","    mdl_mean = blank_only_default.groupby('Component Name')['Calculated Concentration'].mean()\n","    mdl_std = blank_only_default.groupby('Component Name')['Calculated Concentration'].std()\n","    for (index, value) in mdl_mean.items():\n","        mdl.loc[index, 'Mean Concentration'] = value\n","    for (index, value) in mdl_std.items():\n","        mdl.loc[index, 'Std Concentration'] = value\n","    mdl['MDL'] = mdl['Mean Concentration'] + 3 * mdl['Std Concentration']\n","\n","# Load idl values from IDL_IQL file and IDL_2024 file\n","idl_2024 = pd.read_csv(idl_2024_filepath, index_col=0, low_memory=False, nrows=1)\n","idl = pd.read_csv(idl_iql_filepath, skiprows=[2], index_col=0)\n","idl = idl.apply(pd.to_numeric, errors='coerce')\n","\n","# Use idl_2024 and append all values from idl, which are not included in 2024\n","for idl_column in idl.columns:\n","    if idl_column not in idl_2024.columns:\n","        idl_2024[idl_column] = idl[idl_column]\n","\n","idl24_columns = idl_2024.columns\n","\n","# Write each iql value in new column of mdl dataframe\n","for row_index in mdl.index:\n","    if row_index in idl24_columns:\n","        mdl.loc[row_index, 'IDL'] = idl_2024[f'{row_index}'].to_list()[0]\n","    else:\n","        mdl.loc[row_index, 'IDL'] = idl_unknown\n","        print(f'No IDL available for {row_index}, default value of 1e-3 is used.')\n","\n","mdl['Detection Threshold'] = mdl['MDL']\n","mdl['Detection Threshold'].fillna(mdl.IDL, inplace=True)\n","\n","# write detection threshold to excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl', mode='a') as writer:\n","    mdl.to_excel(writer, sheet_name='Detection Threshold')\n","\n","# include detection threshold to long format table data quantification_pfas_default\n","# assign right detection thresholds to right rows.\n","quantification_pfas_default.loc[:, 'Below Detection Threshold'] = [False] * len(quantification_pfas_default)\n","quantification_pfas_default.loc[:, 'Detection Threshold'] = [np.nan] * len(quantification_pfas_default)\n","for row_index in quantification_pfas_default.index:\n","    component_name = quantification_pfas_default.loc[row_index, 'Component Name']\n","    detection_threshold = mdl.loc[component_name, 'Detection Threshold']\n","    # print(detection_threshold)\n","    quantification_pfas_default.loc[row_index, 'Detection Threshold'] = detection_threshold\n","    if quantification_pfas_default.loc[row_index, 'Calculated Concentration'] < detection_threshold:\n","        quantification_pfas_default.loc[row_index, 'Below Detection Threshold'] = True"]},{"cell_type":"markdown","metadata":{"id":"4YKdBVv8RJae"},"source":["# Mass Channel Ratios\n","The following block evaluates ratio of calculated concentration from default channel and _TOF MS channel for all PFAS components and all samples. \\\n","\n","Moreover a column a new column 'Channel Ratio . x' is intrudoced, which indicates all calculated concentration values which deviate more than x % between channels.\\\n","\n","x is the variable 'allowed_channel_deviation' you set in the third code block on top."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5i5K42m8Ra-9"},"outputs":[],"source":["# Assign TOF channel to each PFAS and save calculated concentration to new column\n","quantification_pfas_default.loc[:,'Calculated Concentration TOF'] = [np.nan] * len(quantification_pfas_default)\n","for row_index in quantification_pfas_default.index:\n","    sample_index = quantification_pfas_default.loc[row_index, 'Sample Index']\n","    tof_channel_index = components_default.index(quantification_pfas_default.loc[row_index, 'Component Name'])\n","    tof_channel_name = components_tof[tof_channel_index]\n","    tof_channel_row = quantification_only[(\n","        (quantification_only['Component Name'] == tof_channel_name) &\n","        (quantification_only['Sample Index'] == sample_index)\n","    )]\n","    quantification_pfas_default.loc[row_index, 'Calculated Concentration TOF'] = \\\n","        tof_channel_row.loc[:,'Calculated Concentration'].to_list()[0]\n","\n","# Calculate average deviation of the channels\n","quantification_pfas_default['Channel Ratio'] = (\n","    200 * (quantification_pfas_default['Calculated Concentration'] - quantification_pfas_default['Calculated Concentration TOF']) \\\n","        / (quantification_pfas_default['Calculated Concentration'] + quantification_pfas_default['Calculated Concentration TOF'])\n",").round(decimals=1)\n","\n","# Introduce new column where everything below method detection limit is marked\n","quantification_pfas_default[f'Channel Ratio > {allowed_channel_deviation}'] = abs(quantification_pfas_default['Channel Ratio']) > allowed_channel_deviation\n","\n","# Create pivot table\n","channel_ratio = quantification_pfas_default.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values='Channel Ratio', aggfunc='mean', dropna=False,\n",")\n","channel_ratio.rename(index=index_mapper, inplace=True)\n","channel_ratio = channel_ratio[components_default]\n","\n","# color code percentage deviation\n","def deviation_color_map(val):\n","    if val is np.nan:\n","        return\n","    if allowed_channel_deviation * (-1) <= val <= allowed_channel_deviation:\n","        return in_range\n","    elif val < allowed_channel_deviation * (-1) or val > allowed_channel_deviation:\n","        return out_range\n","\n","channel_ratio = channel_ratio.style.map(deviation_color_map)\n","\n","# write to existing excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl', mode='a') as writer:\n","    channel_ratio.to_excel(writer, sheet_name='Channel Ratio')"]},{"cell_type":"markdown","metadata":{"id":"q7Ag87M8RffX"},"source":["# Outputs\n","The following code block writes final concentration table with all information to excel. It uses concentration values and indicates all values below detection threshold with '< MDL', all channel deviation above x % with '> CR' and all recovery rates below or above the indicated threshold values with 'Poor Recovery'.\n","In addition, concentration values are converted to ng\\g or ng\\l respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFWdAgN-6HGJ"},"outputs":[],"source":["def flag_values(data: pd.DataFrame, column: str) -> pd.DataFrame:\n","    \"\"\"Flags column values (most probably concentrations) with channel ratio, recovery rates and MDLs.\n","\n","    :param data: data frame containing columns 'Channel Ratio', 'Poor Recovery', and 'Below Detection Threshold',\n","    as well as the column you indicated.\n","    :type data: pd.DataFrame\n","    :param column: Colun name of data frame to be filtered or flagged.\n","    :type column: str\n","    :return: Data frame, where the column data is flagged.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    final_table = data[['Sample Name', 'Sample Index', 'Component Name', column]]\n","    final_table.loc[final_table.index[quantification_pfas_default[f'Channel Ratio > {allowed_channel_deviation}']], column] = '> CR'\n","    final_table.loc[final_table.index[quantification_pfas_default['Poor Recovery']], column] = 'Poor Recovery'\n","    final_table.loc[final_table.index[quantification_pfas_default['Below Detection Threshold']], column] = '< MDL'\n","    return final_table\n","\n","# Transform concentration to ng/g or ng/l, depending on your sample_unit\n","quantification_pfas_default[f'Concentration in ng per {sample_unit}'] = quantification_pfas_default['Calculated Concentration'] / nonextracted_sample_quantity\n","\n","# Flag concentration values with channel ratio, recovery rates and detection threshold.\n","calculated_concentration = flag_values(data=quantification_pfas_default, column='Calculated Concentration')\n","calculated_concentration_II = flag_values(data=quantification_pfas_default, column=f'Concentration in ng per {sample_unit}')\n","\n","# Pivot concentration tables.\n","calculated_concentration = calculated_concentration.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values='Calculated Concentration', aggfunc='first', dropna=False,\n",")\n","calculated_concentration.rename(index=index_mapper, inplace=True)\n","calculated_concentration = calculated_concentration[components_default]\n","\n","calculated_concentration_II = calculated_concentration_II.pivot_table(\n","    index=('Sample Index',), columns='Component Name', values=f'Concentration in ng per {sample_unit}', aggfunc='first', dropna=False,\n",")\n","calculated_concentration_II.rename(index=index_mapper, inplace=True)\n","calculated_concentration_II = calculated_concentration_II[components_default]\n","\n","# Write pivot tables to existing excel file\n","with pd.ExcelWriter(processed_filepath_xlsx, engine='openpyxl', mode='a') as writer:\n","    calculated_concentration.to_excel(writer, sheet_name='Concentration Table')\n","    if sample_unit == \"l\":\n","        calculated_concentration_II.to_excel(writer, sheet_name=f'Concentration (ng per l)')\n","    else:\n","        calculated_concentration_II.to_excel(writer, sheet_name=f'Concentration (ng per g)')\n","\n","# Write long format data to csv\n","quantification_pfas_default = quantification_pfas_default[[\n","    'Sample Name', 'Sample Index', 'Acquisition Date & Time','Component Name', 'Area', 'Calculated Concentration',\n","    f'Concentration in ng per {sample_unit}', 'IDA Name', 'IDA Area', 'IDA Concentration', 'IPS Name', 'IPS Area', 'IPS Concentration',\n","    'Recovery Rate', 'Recovery Rate Uncertainty 1', 'Recovery Rate Sciex', 'Detection Threshold', 'Below Detection Threshold',\n","    'Channel Ratio', f'Channel Ratio > {allowed_channel_deviation}', 'Poor Recovery'\n","]]\n","\n","quantification_pfas_default.to_csv(processed_filepath_csv)\n","\n","# Print output\n","calculated_concentration"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}